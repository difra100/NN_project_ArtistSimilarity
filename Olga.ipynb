{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e657a64",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'git'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10160/2807643591.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'git'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from requests_html import HTML,HTMLSession\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from random import choice\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "891c542f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'git' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10160/1050248212.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'git' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ec576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ideas: Take the names from the json file, in order to make the enumeration funny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c407599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'846be3c9-5f94-46ab-97b9-531335dd3658'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olga=pd.read_csv('olga.csv')\n",
    "#olga[olga.partition=='train'].count()   #train 0-14138, #val 14139-15905, #test 15906-17673\n",
    "olga.musicbrainz_id[11902]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3712d1b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class DatasetOlga():\n",
    "    \n",
    "    def __init__(self,olga):\n",
    "        self.olga=olga\n",
    "        self.mb=olga.musicbrainz_id\n",
    "        self.artists={} #Needed for obtaining the mapping from musicbrainz to the allmusic ids\n",
    "        self.l=len(self.mb)\n",
    "        self.d={}       #Needed for obtaining a dict. where keys are artists, and values are the artists similar to them, based on self.artists\n",
    "        self.NI={}      #Dict. that will contain the artist's features\n",
    "    def get_mapping(self,i):\n",
    "        response = requests.get(f'https://musicbrainz.org/ws/2/artist/{str(self.mb[i])}?inc=url-rels&fmt=json')\n",
    "        if response.ok:\n",
    "            data = response.json()\n",
    "            refs = [r['url']['resource'] for r in data['relations'] if r['type'] == 'allmusic']        \n",
    "            return refs[0] if len(refs) != 0 else \"Not found\"\n",
    "\n",
    "        \n",
    "\n",
    "    def get_mappingList(self,init,end,increm=500):\n",
    "        Lmusicbrainz_id=self.mb[init:end]\n",
    "        length=len(Lmusicbrainz_id)\n",
    "        c=0\n",
    "        for i in range(len(Lmusicbrainz_id)):\n",
    "            mapp=self.get_mapping(i)\n",
    "            if mapp==None:\n",
    "                while mapp==None:\n",
    "                    mapp=self.get_mapping(i)\n",
    "                    \n",
    "            if mapp!=\"Not found\":   #Some of the ids has not a respective allmusic id, so we lose that information\n",
    "                mapp=str(mapp)      #Mapp are strings of links\n",
    "                key=mapp[-12:]\n",
    "                self.artists[key]=i\n",
    "            c+=1\n",
    "            if c%increm==0 or c==30:\n",
    "                    print(\"{}/{} artists were processed\".format(c,length))\n",
    "                    \n",
    "            \n",
    "        #self.save_data(self.artists,'MsbMapped1.json')  #We do save the Artists Ids map\n",
    "            \n",
    "        return self.artists\n",
    "    \n",
    "    \n",
    "    def get_GraphDict(self,name='MsbMapped1.json',increm=500):\n",
    "        session=HTMLSession()\n",
    "        c=0 #Counter\n",
    "        artID=self.load_data(name) #We load the mapped artists (between MusicBrainz Ids, and AllMusic Ids)\n",
    "        length=len(artID.keys())\n",
    "        for k in artID.keys(): #dict of mapped mbids, this has to be computed before from getmapping\n",
    "            if k!=None:\n",
    "                url='https://www.allmusic.com/artist/'+ k+ '/related' #k is just the code\n",
    "                r=session.get(url)\n",
    "                sess=r.html.find('body',first=True)\n",
    "                div=sess.find('.overflow-container')\n",
    "                divn=div[0]\n",
    "                divn=divn.find('.content-container')\n",
    "                divn=divn[0]\n",
    "                divn=divn.find('.content')\n",
    "                divn=divn[0]\n",
    "                divn=divn.find('section',first=True)\n",
    "                if divn==None:\n",
    "                    self.d[artID[k]]=[] #That artist has not related artists (or we have missing informations)\n",
    "                    continue\n",
    "                artists=divn.find('li')\n",
    "                artistL=[]\n",
    "\n",
    "\n",
    "                for i in range(len(artists)):\n",
    "                    art=artists[i]\n",
    "                    art=art.find('a')\n",
    "                    link=list(art[0].absolute_links)[0] #Absolute_link return a one-element set, that we convert into a list and\n",
    "                    link=str(link)[-12:] #we get its code\n",
    "                    if link in artID.keys(): #g is the dict of all the mapped musicbrainz_ids\n",
    "                        artistL.append(self.artists[link])\n",
    "                self.d[artID[k]]=artistL\n",
    "                c+=1\n",
    "                if c%increm==0 or c==30:\n",
    "                    print(\"{}/{} artists were processed\".format(c,length))\n",
    "        #self.save_data(self.d,'graphSimilarities1.json') #Here we save the connection amongst the artist, obtained with this method\n",
    "        print(\"Done...\")\n",
    "        return self.d\n",
    "    \n",
    "    def save_data(self,dicti,name):\n",
    "        jfile = open(name, \"w\")\n",
    "        jfile = json.dump(dicti, jfile)\n",
    "    \n",
    "    def load_data(self,name):\n",
    "        jfile = open(name, \"r\")\n",
    "        dicti = json.load(jfile)\n",
    "        return dicti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd6f3ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.allmusic.com/artist/mn0000678420'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=DatasetOlga(olga)\n",
    "d.get_mapping(11902)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145ae3a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_features=2613\n",
    "class Graph():  #The purpose of this class is to construct the graph of artists, in particular the Adjacency matrix A, and the  \n",
    "                # node features tensor X\n",
    "        \n",
    "    def __init__(self,mapfile,gfile):\n",
    "        self.mfile=self.load_data(mapfile)\n",
    "        self.gfile=self.load_data(gfile)\n",
    "        self.A=torch.zeros((len(self.mfile),len(self.mfile)))\n",
    "        self.X=torch.zeros((n_features,len(self.mfile)))\n",
    "        self.ord=sorted(list(map(int,self.gfile.keys())))\n",
    "        self.enc1={}\n",
    "        self.enc2={}\n",
    "        \n",
    "    def encoding1(self):   #From ordered to unordered, Dict are not ordered data structures, so is better to order them before\n",
    "        for k in range(len(self.mfile)): #This encoding is used to get the Instance matrix\n",
    "            self.enc1[k]=self.ord[k]\n",
    "        return self.enc1\n",
    "    \n",
    "    def encoding2(self):   #From unordered to ordered,  From real number, to ordered one.\n",
    "        for k in range(len(self.mfile)): #This encoding is used to get the Adjacency matrix\n",
    "            self.enc2[self.ord[k]]=k\n",
    "        return self.enc2\n",
    "    \n",
    "    def get_instance(self,instances,df=False):#We take the features centroid, obtained from 25 track from artists discographies.\n",
    "        X=np.load(instances)\n",
    "        X=torch.from_numpy(X).requires_grad_(True)  #We take the allmusicIDs, which contain the key of the artists for which we don't \n",
    "        c=0                    # have lost the informations\n",
    "        enc=self.encoding1()\n",
    "        for k in self.mfile:\n",
    "            z=enc[c]\n",
    "            self.X[:,c]=X[z] \n",
    "            c+=1\n",
    "        return self.X\n",
    "    \n",
    "    def get_adjacency(self,symmetry=False,df=False):  #The hypothesis could be either a symmetric matrix (paper), or not.\n",
    "        enc=self.encoding2()\n",
    "        for k in self.gfile:\n",
    "            c1=enc[int(k)]\n",
    "            for j in self.gfile[k]:\n",
    "                c2=enc[int(j)]\n",
    "                if self.A[c2,c1]==1 and symmetry==True:\n",
    "                    continue\n",
    "                self.A[c1,c2]=1\n",
    "                if symmetry:\n",
    "                    self.A[c2,c1]=1\n",
    "\n",
    "            \n",
    "        return self.A\n",
    "    \n",
    "    \n",
    "    def load_data(self,name):\n",
    "        jfile = open(name, \"r\")\n",
    "        dicti = json.load(jfile)\n",
    "        return dicti\n",
    "    \n",
    "g=Graph('MsbMapped.json','graphSimilarities.json')\n",
    "X1=g.get_instance('acousticbrainz.npy')\n",
    "A1=g.get_adjacency(symmetry=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c34cc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9021"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=list(range(0,9021+1))\n",
    "l[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1121362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we have some hyperparamters, and also the list of ordered artists, and their indices with respect their own set (train,val,test).\n",
    "outf=[2613,512,128,32,100] #Train: 0:9021, #Val: 9022:10189, #Test: 10190:11260\n",
    "train_=list(range(0,9021+1)) #Train set, without val\n",
    "train=list(range(0,10189+1)) #Train set, with val\n",
    "val=list(range(9022,10189+1))\n",
    "test=list(range(10190,11260+1))\n",
    "KNN=200\n",
    "device=torch.device('cuda')\n",
    "class GraphSAGE(nn.Module):\n",
    "    \n",
    "    def __init__(self,X,A):\n",
    "        super(GraphSAGE,self).__init__()\n",
    "        self.A=A #Tensors version of adjacency matrix and Instances\n",
    "        self.X=X    \n",
    "        self.V={}  #In this dictionary we insert the tracing of a certain mini_batch, needed for the forward step\n",
    "        self.l11=nn.Linear(outf[0],1024)\n",
    "        self.l12=nn.Linear(3637,outf[1])\n",
    "        self.l21=nn.Linear(outf[1],256)\n",
    "        self.l22=nn.Linear(768,outf[2])\n",
    "        self.l31=nn.Linear(outf[2],64)\n",
    "        self.l32=nn.Linear(192,outf[3])\n",
    "        self.FC11=nn.Linear(outf[1],256)\n",
    "        self.FC12=nn.Linear(outf[2],256)\n",
    "        self.FC13=nn.Linear(outf[3],256)\n",
    "        \n",
    "        self.FC2=nn.Linear(256,256)\n",
    "        self.out=nn.Linear(256,100) #final output layer\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self,V,L):\n",
    "        K=L+1  #We add a number, because if we have three layer, we need to count also the batch\n",
    "        self.V[K]=set(V)\n",
    "        for k in range(K-1,0,-1):\n",
    "            d=set()\n",
    "            for idx in self.V[k+1]: \n",
    "                \n",
    "                d=d.union(self.get_n(idx))\n",
    "                \n",
    "            self.V[k]=d\n",
    "        \n",
    "        Es=self.select(self.X,set(),self.V[1])\n",
    "        for k in range(0,K-1): #k starts from 0, 0 is associated with the first layer, 1 with the second and so on....\n",
    "            #print(\"Graph convolutional layer n° {}, processing...\".format(k+1))\n",
    "            t=self.tfunc(outf[k],Es,self.V[k+1]) #tfunc is a matrix that has 0 for the column outside the mini-batch sets\n",
    "            Esn=self.select(t,set(),self.V[k+2]) #and has the transformed vectors for the columns that belongs to the mini_batch set\n",
    "            An=self.select(self.A,self.V[k+1],self.V[k+2]) #We do select either the vectors from X, and from A\n",
    "            if k==0:\n",
    "                N=torch.mm(torch.transpose(F.elu(self.l11(torch.transpose(Es,0,1))),0,1),An)\n",
    "                \n",
    "                Es=F.elu(self.l12(torch.transpose(torch.cat((N,Esn)),0,1)))\n",
    "            if k==1:\n",
    "                N=torch.mm(torch.transpose(F.elu(self.l21(torch.transpose(Es,0,1))),0,1),An)\n",
    "                \n",
    "                Es=F.elu(self.l22(torch.transpose(torch.cat((N,Esn)),0,1)))\n",
    "            if k==2:\n",
    "                N=torch.mm(torch.transpose(F.elu(self.l31(torch.transpose(Es,0,1))),0,1),An)\n",
    "                \n",
    "                Es=F.elu(self.l32(torch.transpose(torch.cat((N,Esn)),0,1)))\n",
    "            \n",
    "            Es=torch.transpose(F.normalize(Es,dim=0),0,1)\n",
    "        if L==1:                                         #There are different input dimensions, because they depend on the \n",
    "            Es=F.elu(self.FC11(torch.transpose(Es,0,1))) #output dimension returned by the GCN\n",
    "        elif L==2:\n",
    "            Es=F.elu(self.FC12(torch.transpose(Es,0,1)))\n",
    "        elif L==3:\n",
    "            Es=F.elu(self.FC13(torch.transpose(Es,0,1)))\n",
    "        Es=F.elu(self.FC2(Es))\n",
    "        Es=torch.transpose(self.out(Es),0,1) #Final linear layer that represent the obtained embedded space.\n",
    "#         print(Es)\n",
    "#         print(Es.shape)\n",
    "        return Es\n",
    "            \n",
    "    def get_n(self,idx):    #This function is the neighbors function. Given a batch index we get its neighborhood.\n",
    "        t=torch.nonzero(self.A[idx])\n",
    "        s=set()\n",
    "        \n",
    "        for k in t:\n",
    "            if t.shape[0]!=0:\n",
    "                s.add(k.item())\n",
    "        s.add(idx)     \n",
    "                \n",
    "        return s\n",
    "    def select(self,mat,row,col):  #Given a set of indices for rows or column or both, we get the respective elements.\n",
    "        col=sorted(list(col))      #This is applied when we get the t matrix.\n",
    "        \n",
    "        c=0\n",
    "        if row==set():\n",
    "            ma=torch.zeros((mat.shape[0],len(col)))\n",
    "            for k in col:\n",
    "                ma[:,c]=mat[:,k]\n",
    "                c+=1\n",
    "            return ma\n",
    "        else:\n",
    "            row=torch.tensor(sorted(list(row)))\n",
    "            col=torch.tensor(col)\n",
    "            ma=torch.index_select(mat,0,row)\n",
    "            ma=torch.index_select(ma,1,col)\n",
    "            return ma\n",
    "    def tfunc(self,n_feat,es,V):               #This is the t function, and it is previously described\n",
    "        t=torch.zeros((n_feat,self.X.shape[1]))\n",
    "        V=sorted(list(V))\n",
    "        c=0\n",
    "        for k in V:\n",
    "            t[:,k]=es[:,c]\n",
    "            c+=1\n",
    "        return t\n",
    "    def tfunc2(self,n_feat,es,V,prev):               #This is the t function, and it is previously described\n",
    "        #t=torch.zeros((n_feat,self.X.shape[1]))\n",
    "        V=sorted(list(V))\n",
    "        c=0\n",
    "        for k in V:\n",
    "            prev[:,k]=es[:,c]\n",
    "            c+=1\n",
    "        return prev\n",
    "    def mini_batches(self,indices,bs=32): #This function generates a list of minibatches, of size bs\n",
    "        indicesN=indices.copy()\n",
    "        mbList=[] #Lists of lists of mini_batches indices \n",
    "        while len(indicesN)!=0:\n",
    "            mb=set()  #Inner list, with the indices of a particular mini_batch\n",
    "            while len(mb)<bs:\n",
    "                if len(indicesN)==0:\n",
    "                    mbList.append(mb)\n",
    "                    return mbList\n",
    "                r=choice(indicesN)\n",
    "                sample=indicesN.pop(indicesN.index(r))\n",
    "                mb.add(sample)\n",
    "            mbList.append(mb)\n",
    "        return mbList          #obj.mini_batches(#,bs=128) #: train_,train,val,test, we get lists of list of batches from here\n",
    "    \n",
    "    \n",
    "    def calcG(self,ID):\n",
    "        if ID>200:\n",
    "            ID=200\n",
    "        c=1\n",
    "        somm=0\n",
    "        while c<=ID:\n",
    "            somm+=1/(math.log2(1+c))\n",
    "            c+=1\n",
    "        return somm\n",
    "\n",
    "    def evalAcc(self,T,S,kneigh):\n",
    "        T=T.detach().numpy().transpose()\n",
    "        neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(T)\n",
    "        dist,ind=neigh.kneighbors(T)\n",
    "        acc=[]\n",
    "        for k in S:\n",
    "            summ=0\n",
    "            ideal=self.A[k,:].sum().item()  #gs\n",
    "            den=self.calcG(ideal)\n",
    "            c=1\n",
    "            if den==0:#There is the problem of the distance for the people without neighboorhood\n",
    "                continue\n",
    "            for j in ind[k][1:]:\n",
    "                if self.A[k][j]!=0:\n",
    "                    summ+= 1/(math.log2(1+c))\n",
    "                else:\n",
    "                    continue\n",
    "                c+=1\n",
    "            summ/=den\n",
    "            acc.append(summ)\n",
    "        return acc\n",
    "\n",
    "\n",
    "gs=GraphSAGE(X1,A1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ff785ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "training=train_\n",
    "testing=val\n",
    "n_layer=1\n",
    "batch_size=512 #This is the batch size used in the paper which insired artist similarity\n",
    "mbb=gs.mini_batches(training,bs=batch_size)\n",
    "num_epochs=1 #50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e580b5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch n°  1\n",
      "Evaluating the epoch n°  1\n",
      "Processesed epoch n° 1, \tTrain accuracy: 0.2365, \tTest accuracy: 0.3087\n",
      "done\n",
      "73.32841181755066\n"
     ]
    }
   ],
   "source": [
    "#With these lines of code we obtain the embedded space sample\n",
    "start=time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Processing epoch n° \",epoch+1)\n",
    "    num=int(len(training)/batch_size)+1     \n",
    "    for k in range(len(mbb)):\n",
    "        Ex=gs(mbb[k],n_layer)\n",
    "        #TODO: Loss function, Optimizer\n",
    "        name=\"C:\\\\Users\\\\Peppe\\\\OneDrive\\\\Desktop\\\\Università\\\\magistrale\\\\Neural_Networks\\\\MIR_project\\\\minibatches\\\\file\"+str(k)+\".pt\"\n",
    "        torch.save(Ex,name)\n",
    "\n",
    "    for k in range(len(mbb)):\n",
    "        name=\"C:\\\\Users\\\\Peppe\\\\OneDrive\\\\Desktop\\\\Università\\\\magistrale\\\\Neural_Networks\\\\MIR_project\\\\minibatches\\\\file\"+str(k)+\".pt\"\n",
    "        ex=torch.load(name)\n",
    "        \n",
    "        if k==0:\n",
    "            t1=gs.tfunc(outf[-1],ex,mbb[k])\n",
    "\n",
    "        else:\n",
    "            t1=gs.tfunc2(outf[-1],ex,mbb[k],t1)\n",
    "    print(\"Evaluating the epoch n° \",epoch+1)\n",
    "    accL1=gs.evalAcc(t1[:,:training[-1]+1],set(training),KNN)\n",
    "    t2=gs(set(testing),n_layer)\n",
    "    t2=gs.tfunc2(outf[-1],t2,set(testing),t1) #We integrate the testing set to the previous training set\n",
    "    accL2=gs.evalAcc(t2,set(testing),KNN)\n",
    "    TestAcc=sum(accL1)/len(accL1)\n",
    "    TrainAcc=sum(accL2)/len(accL2)\n",
    "    print(\"Processesed epoch n° {}, \\tTrain accuracy: {:.4f}, \\tTest accuracy: {:.4f}\".format((epoch+1),TrainAcc,TestAcc))\n",
    "    print(\"done\")\n",
    "end=time.time()\n",
    "print(end-start) #78 sec (1 graph layer), 132 sec (2 graph layers), 214 sec (3 graph layers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dff5897",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.5527849978433516,\n",
       " 0.2478157200914361,\n",
       " 0.5803167071934787,\n",
       " 0.0,\n",
       " 0.5505591812421098,\n",
       " 0.3391602052736161,\n",
       " 0.30260241349881345,\n",
       " 0.5637884576902256,\n",
       " 0.0,\n",
       " 0.7738292444290639,\n",
       " 0.0,\n",
       " 0.41952291583572193,\n",
       " 0.0,\n",
       " 0.2906484777184987,\n",
       " 0.5029917276850138,\n",
       " 0.5857421563596757,\n",
       " 0.8310649966911269,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.5029917276850138,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5030343053984369,\n",
       " 0.5527849978433516,\n",
       " 0.5148915307328632,\n",
       " 0.9003541785812085,\n",
       " 0.0,\n",
       " 0.7606798040475855,\n",
       " 0.7078800465594848,\n",
       " 0.0,\n",
       " 0.6744974905851283,\n",
       " 0.0,\n",
       " 0.3903800499921017,\n",
       " 0.6744974905851283,\n",
       " 0.0,\n",
       " 0.46927872602275644,\n",
       " 0.4565046246555299,\n",
       " 0.38334277998463445,\n",
       " 0.7475474611262282,\n",
       " 0.2529427027676571,\n",
       " 0.3903800499921017,\n",
       " 0.6585765334200407,\n",
       " 0.5637884576902256,\n",
       " 0.0,\n",
       " 0.39614437854106904,\n",
       " 0.685530555364185,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.647939623894138,\n",
       " 0.41253177989255346,\n",
       " 0.3903800499921017,\n",
       " 0.0,\n",
       " 0.6704414151758369,\n",
       " 0.6131471927654584,\n",
       " 0.0,\n",
       " 0.4483039899025303,\n",
       " 0.5789533463717488,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.45151815934378775,\n",
       " 0.0,\n",
       " 0.19635793579928928,\n",
       " 0.0,\n",
       " 0.647939623894138,\n",
       " 0.38334277998463445,\n",
       " 0.5505591812421098,\n",
       " 0.0,\n",
       " 0.31501231715169875,\n",
       " 0.647939623894138,\n",
       " 0.5390031312763821,\n",
       " 0.5889255678238341,\n",
       " 0.504455295936708,\n",
       " 0.0,\n",
       " 0.3391602052736161,\n",
       " 0.520763430001022,\n",
       " 0.7967867090175138,\n",
       " 0.22009176629808017,\n",
       " 0.46939493307846425,\n",
       " 0.6104884152125465,\n",
       " 0.4565046246555299,\n",
       " 0.7382215928042347,\n",
       " 0.6585765334200407,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.7861009659566677,\n",
       " 0.758194735610121,\n",
       " 0.23504554941448536,\n",
       " 0.3903800499921017,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6669348828794692,\n",
       " 0.0,\n",
       " 0.5789533463717488,\n",
       " 0.0,\n",
       " 0.48600123552531926,\n",
       " 0.0,\n",
       " 0.44124807927831455,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.32024599984493496,\n",
       " 0.0,\n",
       " 0.41253177989255346,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6474722340862189,\n",
       " 0.0,\n",
       " 0.3237894766400435,\n",
       " 0.800693766409882,\n",
       " 0.6930221935231562,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.8025357882215017,\n",
       " 0.22009176629808017,\n",
       " 0.44124807927831455,\n",
       " 0.0,\n",
       " 0.38334277998463445,\n",
       " 0.42752974425480034,\n",
       " 0.4935232796777481,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.4565046246555299,\n",
       " 0.0,\n",
       " 0.41879925010384716,\n",
       " 0.2529427027676571,\n",
       " 0.4748461821196943,\n",
       " 0.0,\n",
       " 0.823672244902574,\n",
       " 0.0,\n",
       " 0.7436050723246855,\n",
       " 0.8104616303452685,\n",
       " 0.8229038656134148,\n",
       " 0.7751482523375255,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6060150995320358,\n",
       " 0.7300033028682728,\n",
       " 0.8318724637288826,\n",
       " 0.714350099615581,\n",
       " 0.22009176629808017,\n",
       " 0.46927872602275644,\n",
       " 0.23504554941448536,\n",
       " 0.5531464700081437,\n",
       " 0.5531464700081437,\n",
       " 0.3903800499921017,\n",
       " 0.0,\n",
       " 0.7327672289198516,\n",
       " 0.5944433738938649,\n",
       " 0.46927872602275644,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6474722340862189,\n",
       " 0.6814934387125502,\n",
       " 0.7606993035979727,\n",
       " 0.0,\n",
       " 0.6224938935861938,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.41842496774457966,\n",
       " 0.27487633291429087,\n",
       " 0.6610788125463339,\n",
       " 0.4690000933206748,\n",
       " 0.2906484777184987,\n",
       " 0.0,\n",
       " 0.45151815934378775,\n",
       " 0.0,\n",
       " 0.3391602052736161,\n",
       " 0.5637884576902256,\n",
       " 0.5889255678238341,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5889255678238341,\n",
       " 0.7738292444290639,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2529427027676571,\n",
       " 0.0,\n",
       " 0.6694141425968754,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5889255678238341,\n",
       " 0.7516294360146978,\n",
       " 0.38334277998463445,\n",
       " 0.0,\n",
       " 0.38922970858856365,\n",
       " 0.0,\n",
       " 0.8643725870518096,\n",
       " 0.27487633291429087,\n",
       " 0.41842496774457966,\n",
       " 0.0,\n",
       " 0.714350099615581,\n",
       " 0.5008655546918772,\n",
       " 0.0,\n",
       " 0.6366824387328317,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.30260241349881345,\n",
       " 0.46939493307846425,\n",
       " 0.5121242942479061,\n",
       " 0.0,\n",
       " 0.4483039899025303,\n",
       " 0.6230038228261526,\n",
       " 0.0,\n",
       " 0.725855982823772,\n",
       " 0.0,\n",
       " 0.5489114385132179,\n",
       " 0.5857421563596757,\n",
       " 0.32024599984493496,\n",
       " 0.5442161020480354,\n",
       " 0.520763430001022,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.568358931899782,\n",
       " 0.4214684689121348,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.12980807103224343,\n",
       " 0.33580101130045265,\n",
       " 0.0,\n",
       " 0.3391602052736161,\n",
       " 0.4935232796777481,\n",
       " 0.822763344775578,\n",
       " 0.41842496774457966,\n",
       " 0.34898956158698663,\n",
       " 0.6610788125463339,\n",
       " 0.0,\n",
       " 0.644824486427155,\n",
       " 0.2906484777184987,\n",
       " 0.23504554941448536,\n",
       " 0.23504554941448536,\n",
       " 0.30260241349881345,\n",
       " 0.6464598605492695,\n",
       " 0.7085912584660702,\n",
       " 0.647939623894138,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.17821029819465137,\n",
       " 0.0,\n",
       " 0.7233730536811409,\n",
       " 0.0,\n",
       " 0.4361024602212408,\n",
       " 0.22009176629808017,\n",
       " 0.27487633291429087,\n",
       " 0.32024599984493496,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.7045480903173083,\n",
       " 0.2073612289146658,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3391602052736161,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.7606798040475855,\n",
       " 0.3655788134394874,\n",
       " 0.5029917276850138,\n",
       " 0.5977176549417553,\n",
       " 0.41253177989255346,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6007191013404622,\n",
       " 0.42897235858547583,\n",
       " 0.0,\n",
       " 0.27487633291429087,\n",
       " 0.0,\n",
       " 0.568358931899782,\n",
       " 0.34898956158698663,\n",
       " 0.5340106033228957,\n",
       " 0.0,\n",
       " 0.3589542101716347,\n",
       " 0.2529427027676571,\n",
       " 0.17060921827860473,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.4052182764476915,\n",
       " 0.0,\n",
       " 0.4783230211921073,\n",
       " 0.0,\n",
       " 0.5856545341301653,\n",
       " 0.5390031312763821,\n",
       " 0.6442179742177578,\n",
       " 0.0,\n",
       " 0.714350099615581,\n",
       " 0.3903800499921017,\n",
       " 0.6483290005553846,\n",
       " 0.0,\n",
       " 0.5311778327782406,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.38922970858856365,\n",
       " 0.0,\n",
       " 0.18672776492534796,\n",
       " 0.5390031312763821,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6793155414495853,\n",
       " 0.3903800499921017,\n",
       " 0.0,\n",
       " 0.4483039899025303,\n",
       " 0.0,\n",
       " 0.3381915979740705,\n",
       " 0.0,\n",
       " 0.38334277998463445,\n",
       " 0.76724922449719,\n",
       " 0.725855982823772,\n",
       " 0.3589542101716347,\n",
       " 0.0,\n",
       " 0.38334277998463445,\n",
       " 0.0,\n",
       " 0.32024599984493496,\n",
       " 0.27487633291429087,\n",
       " 0.0,\n",
       " 0.4041400325232136,\n",
       " 0.3824677422011651,\n",
       " 0.499236617967808,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.7227265726449519,\n",
       " 0.0,\n",
       " 0.6488974543491512,\n",
       " 0.6254458949421859,\n",
       " 0.22009176629808017,\n",
       " 0.0,\n",
       " 0.7183498011981129,\n",
       " 0.0,\n",
       " 0.7319519652168142,\n",
       " 0.40366886264658747,\n",
       " 0.0,\n",
       " 0.684988415515758,\n",
       " 0.3903800499921017,\n",
       " 0.7599004498434577,\n",
       " 0.39709299330607084,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.581632838561897,\n",
       " 0.5278967437072324,\n",
       " 0.0,\n",
       " 0.6254458949421859,\n",
       " 0.3964444903044841,\n",
       " 0.8603689639972604,\n",
       " 0.32024599984493496,\n",
       " 0.4565046246555299,\n",
       " 0.8822172103714233,\n",
       " 0.38334277998463445,\n",
       " 0.4154187387939456,\n",
       " 0.4370336503672679,\n",
       " 0.3903800499921017,\n",
       " 0.5254457787902355,\n",
       " 0.6113961062954835,\n",
       " 0.7508822647367664,\n",
       " 0.46927872602275644,\n",
       " 0.4935232796777481,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.532723414880825,\n",
       " 0.7944322510700572,\n",
       " 0.3797536268158244,\n",
       " 0.6089771946776426,\n",
       " 0.5311778327782406,\n",
       " 0.0,\n",
       " 0.6431023984609371,\n",
       " 0.0,\n",
       " 0.5029917276850138,\n",
       " 0.644824486427155,\n",
       " 0.6814934387125502,\n",
       " 0.46939493307846425,\n",
       " 0.6696263283365618,\n",
       " 0.0,\n",
       " 0.6262773318390784,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.74459075158332,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.528144263310592,\n",
       " 0.8318724637288826,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.7520383950592918,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.727329844310522,\n",
       " 0.7045480903173083,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3638506620318613,\n",
       " 0.40366886264658747,\n",
       " 0.4483039899025303,\n",
       " 0.41842496774457966,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5412163603163845,\n",
       " 0.3237894766400435,\n",
       " 0.3030586077620556,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6366824387328317,\n",
       " 0.6020941629041773,\n",
       " 0.44187221243140345,\n",
       " 0.353003012121292,\n",
       " 0.30260241349881345,\n",
       " 0.27487633291429087,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5803167071934787,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5385285260252877,\n",
       " 0.5030343053984369,\n",
       " 0.0,\n",
       " 0.6464598605492695,\n",
       " 0.5008655546918772,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.520763430001022,\n",
       " 0.4483039899025303,\n",
       " 0.0,\n",
       " 0.2350445318310892,\n",
       " 0.589790673297785,\n",
       " 0.0,\n",
       " 0.7327672289198516,\n",
       " 0.30260241349881345,\n",
       " 0.489613501543845,\n",
       " 0.23504554941448536,\n",
       " 0.4173075092471356,\n",
       " 0.0,\n",
       " 0.3045398676346468,\n",
       " 0.3237894766400435,\n",
       " 0.3391602052736161,\n",
       " 0.5505591812421098,\n",
       " 0.7543800760006613,\n",
       " 0.5029917276850138,\n",
       " 0.4935232796777481,\n",
       " 0.46927872602275644,\n",
       " 0.0,\n",
       " 0.4783230211921073,\n",
       " 0.5254457787902355,\n",
       " 0.725855982823772,\n",
       " 0.538241803194679,\n",
       " 0.0,\n",
       " 0.18672776492534796,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5030343053984369,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6930221935231562,\n",
       " 0.15194751309721466,\n",
       " 0.7608502772708737,\n",
       " 0.3903800499921017,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.8137381880941051,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.0,\n",
       " 0.4058715898896693,\n",
       " 0.0,\n",
       " 0.5737527650095612,\n",
       " 0.7045480903173083,\n",
       " 0.6967729330112914,\n",
       " 0.2570088759103378,\n",
       " 0.5414808177726183,\n",
       " 0.22009176629808017,\n",
       " 0.41416413751241044,\n",
       " 0.0,\n",
       " 0.18672776492534796,\n",
       " 0.4483039899025303,\n",
       " 0.3635562594634462,\n",
       " 0.0,\n",
       " 0.30260241349881345,\n",
       " 0.5889255678238341,\n",
       " 0.5125537536432211,\n",
       " 0.0,\n",
       " 0.6230038228261526,\n",
       " 0.3979037500973208,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.27487633291429087,\n",
       " 0.0,\n",
       " 0.5531464700081437,\n",
       " 0.4483039899025303,\n",
       " 0.0,\n",
       " 0.1420400396336573,\n",
       " 0.7010436893287377,\n",
       " 0.23504554941448536,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5780938204694294,\n",
       " 0.19635793579928928,\n",
       " 0.0,\n",
       " 0.7520383950592918,\n",
       " 0.0,\n",
       " 0.23939908411991156,\n",
       " 0.0,\n",
       " 0.7603573597118609,\n",
       " 0.0,\n",
       " 0.22009176629808017,\n",
       " 0.0,\n",
       " 0.1637733768567814,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.8097090645058169,\n",
       " 0.8029742804089286,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.650426629181,\n",
       " 0.0,\n",
       " 0.3381915979740705,\n",
       " 0.19635793579928928,\n",
       " 0.3589542101716347,\n",
       " 0.5030343053984369,\n",
       " 0.7724328680004456,\n",
       " 0.0,\n",
       " 0.27487633291429087,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5958074859353116,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.3655788134394874,\n",
       " 0.3760101889984272,\n",
       " 0.6020941629041773,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3045398676346468,\n",
       " 0.41253177989255346,\n",
       " 0.0,\n",
       " 0.5442161020480354,\n",
       " 0.5815090371936308,\n",
       " 0.0,\n",
       " 0.30260241349881345,\n",
       " 0.6255254955064182,\n",
       " 0.0,\n",
       " 0.5531464700081437,\n",
       " 0.617072953141136,\n",
       " 0.3635562594634462,\n",
       " 0.0,\n",
       " 0.569776589011004,\n",
       " 0.0,\n",
       " 0.3979037500973208,\n",
       " 1.0,\n",
       " 0.42752974425480034,\n",
       " 0.0,\n",
       " 0.4565046246555299,\n",
       " 0.0,\n",
       " 0.4152194883391084,\n",
       " 0.38334277998463445,\n",
       " 0.0,\n",
       " 0.1637733768567814,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6930221935231562,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.4646307801739275,\n",
       " 0.0,\n",
       " 0.5085335881210599,\n",
       " 0.5531464700081437,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2529427027676571,\n",
       " 0.8550377607874722,\n",
       " 0.4063897663469566,\n",
       " 0.6488974543491512,\n",
       " 0.15194751309721466,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2529427027676571,\n",
       " 0.0,\n",
       " 0.2073612289146658,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2933341830949182,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.23504554941448536,\n",
       " 0.30260241349881345,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.7751731068737074,\n",
       " 0.2570088759103378,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.17821029819465137,\n",
       " 0.44361797877463205,\n",
       " 0.0,\n",
       " 0.5008655546918772,\n",
       " 0.5958074859353116,\n",
       " 0.6139091417869061,\n",
       " 0.0,\n",
       " 0.3391602052736161,\n",
       " 0.3638506620318613,\n",
       " 0.0,\n",
       " 0.714350099615581,\n",
       " 0.46927872602275644,\n",
       " 0.0,\n",
       " 0.663843923293673,\n",
       " 0.0,\n",
       " 0.3391602052736161,\n",
       " 0.5889255678238341,\n",
       " 0.27487633291429087,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.27487633291429087,\n",
       " 0.6069751706753403,\n",
       " 0.34898956158698663,\n",
       " 0.0,\n",
       " 0.4690000933206748,\n",
       " 0.5254457787902355,\n",
       " 0.7382215928042347,\n",
       " 0.0,\n",
       " 0.30260241349881345,\n",
       " 0.46927872602275644,\n",
       " 0.2570088759103378,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6113961062954835,\n",
       " 0.0,\n",
       " 0.67527069359192,\n",
       " 0.5446557454501227,\n",
       " 0.5638065351361572,\n",
       " 0.7078800465594848,\n",
       " 0.0,\n",
       " 0.3391602052736161,\n",
       " 0.7762941316384039,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.7159934850393549,\n",
       " 0.5246400552358531,\n",
       " 0.7078800465594848,\n",
       " 0.6131232013918976,\n",
       " 0.5637884576902256,\n",
       " 0.6419733299353724,\n",
       " 0.6138227974243602,\n",
       " 0.7030030387658378,\n",
       " 0.5527849978433516,\n",
       " 0.5008655546918772,\n",
       " 0.3045398676346468,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.51674161295635,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3903800499921017,\n",
       " 0.27487633291429087,\n",
       " 0.46927872602275644,\n",
       " 0.5030343053984369,\n",
       " 0.6483290005553846,\n",
       " 0.7457912185292983,\n",
       " 0.568358931899782,\n",
       " 0.7160846096048157,\n",
       " 0.5505591812421098,\n",
       " 0.5008655546918772,\n",
       " 0.27487633291429087,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6113961062954835,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.30260241349881345,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.46927872602275644,\n",
       " 0.6206762745623587,\n",
       " 0.7970360920361244,\n",
       " 0.23165732683700077,\n",
       " 0.0,\n",
       " 0.8550956239938448,\n",
       " 0.6007191013404622,\n",
       " 0.27825165032414384,\n",
       " 0.0,\n",
       " 0.6540187328194402,\n",
       " 0.7653606369886217,\n",
       " 0.5737527650095612,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5008655546918772,\n",
       " 0.27487633291429087,\n",
       " 0.0,\n",
       " 0.3589542101716347,\n",
       " 0.0,\n",
       " 0.6453673484599424,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5029917276850138,\n",
       " 0.41253177989255346,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.19635793579928928,\n",
       " 0.36891452101698013,\n",
       " 0.3391602052736161,\n",
       " 0.5008655546918772,\n",
       " 0.0,\n",
       " 0.758194735610121,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2529427027676571,\n",
       " 0.6900528497151619,\n",
       " 0.5481120504973126,\n",
       " 0.6442392250095603,\n",
       " 0.41952291583572193,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5638065351361572,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5311778327782406,\n",
       " 0.3903800499921017,\n",
       " 0.2529427027676571,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5206989490614421,\n",
       " 0.4935232796777481,\n",
       " 0.6562910973249896,\n",
       " 0.677856761410069,\n",
       " 0.0,\n",
       " 0.5857421563596757,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.30260241349881345,\n",
       " 0.0,\n",
       " 0.5008655546918772,\n",
       " 0.0,\n",
       " 0.6669348828794692,\n",
       " 0.0,\n",
       " 0.7767475730507347,\n",
       " 0.6488974543491512,\n",
       " 0.0,\n",
       " 0.6585765334200407,\n",
       " 0.21170784530020303,\n",
       " 0.7608502772708737,\n",
       " 0.5412163603163845,\n",
       " 0.4549054653929552,\n",
       " 0.6131471927654584,\n",
       " 0.4783230211921073,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5638065351361572,\n",
       " 0.0,\n",
       " 0.7587908504646494,\n",
       " 0.46927872602275644,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.46927872602275644,\n",
       " 0.6131471927654584,\n",
       " 0.647939623894138,\n",
       " 0.4483039899025303,\n",
       " 0.6206762745623587,\n",
       " 0.758194735610121,\n",
       " 0.8701249883466593,\n",
       " 0.6793155414495853,\n",
       " 0.44187221243140345,\n",
       " 0.2073612289146658,\n",
       " 0.5977176549417553,\n",
       " 0.0,\n",
       " 0.27487633291429087,\n",
       " 0.5390031312763821,\n",
       " 0.4690000933206748,\n",
       " 0.7926078922202333,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.46927872602275644,\n",
       " 0.6263548016201019,\n",
       " 0.38334277998463445,\n",
       " 0.27487633291429087,\n",
       " 0.7389572554166463,\n",
       " 0.5640294126772963,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.17821029819465137,\n",
       " 0.23504554941448536,\n",
       " 0.1467868763787456,\n",
       " 0.4483039899025303,\n",
       " 0.6967729330112914,\n",
       " 0.0,\n",
       " 0.7475474611262282,\n",
       " 0.6230038228261526,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.32024599984493496,\n",
       " 0.3391602052736161,\n",
       " 0.27487633291429087,\n",
       " 0.617072953141136,\n",
       " 0.7653606369886217,\n",
       " 0.6113961062954835,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.7543800760006613,\n",
       " 0.0,\n",
       " 0.35261917647813784,\n",
       " 0.22009176629808017,\n",
       " 0.7496213112617068,\n",
       " 0.4483039899025303,\n",
       " 0.5531464700081437,\n",
       " 0.714350099615581,\n",
       " 0.5008655546918772,\n",
       " 0.38334277998463445,\n",
       " 0.7599505057190774,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3381915979740705,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5527849978433516,\n",
       " 0.19635793579928928,\n",
       " 0.6613399691847014,\n",
       " 0.0,\n",
       " 0.647939623894138,\n",
       " 0.7078800465594848,\n",
       " 0.7866867152185787,\n",
       " 0.8354037602006522,\n",
       " 0.4748461821196943,\n",
       " 0.0,\n",
       " 0.6900655744490334,\n",
       " 0.5977176549417553,\n",
       " 0.5857421563596757,\n",
       " 0.6124868592426146,\n",
       " 0.3784069907407894,\n",
       " 0.727329844310522,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.8093223877848527,\n",
       " 0.0,\n",
       " 0.4483039899025303,\n",
       " 0.6967729330112914,\n",
       " 0.4690000933206748,\n",
       " 0.6967729330112914,\n",
       " 0.23504554941448536,\n",
       " 0.0,\n",
       " 0.647939623894138,\n",
       " 0.5527849978433516,\n",
       " 0.0,\n",
       " 0.46927872602275644,\n",
       " 0.7457912185292983,\n",
       " 0.6366824387328317,\n",
       " 0.663843923293673,\n",
       " 0.0,\n",
       " 0.3045398676346468,\n",
       " 0.3387184023763004,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3391602052736161,\n",
       " 0.3391602052736161,\n",
       " 0.22009176629808017,\n",
       " 0.6131471927654584,\n",
       " 0.41253177989255346,\n",
       " 0.0,\n",
       " 0.27487633291429087,\n",
       " 0.44801103058252845,\n",
       " 0.0,\n",
       " 0.3903800499921017,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.27487633291429087,\n",
       " 0.46927872602275644,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.32024599984493496,\n",
       " 0.38334277998463445,\n",
       " 0.0,\n",
       " 0.5030343053984369,\n",
       " 0.30260241349881345,\n",
       " 0.0,\n",
       " 0.3903800499921017,\n",
       " 0.48617541748483384,\n",
       " 0.0,\n",
       " 0.6442392250095603,\n",
       " 0.0,\n",
       " 0.644824486427155,\n",
       " 0.4483039899025303,\n",
       " 0.0,\n",
       " 0.8157017946197568,\n",
       " 0.19635793579928928,\n",
       " 0.41842496774457966,\n",
       " 0.23165732683700077,\n",
       " 0.0,\n",
       " 0.5531464700081437,\n",
       " 0.0,\n",
       " 0.46927872602275644,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6397747256990975,\n",
       " 0.7767471075223497,\n",
       " 0.4739185741627291,\n",
       " 0.23504554941448536,\n",
       " 0.7082590236391592,\n",
       " 0.7188631284189716,\n",
       " 0.0,\n",
       " 0.38334277998463445,\n",
       " 0.7751482523375255,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.431156588849703,\n",
       " 0.32024599984493496,\n",
       " 0.647939623894138,\n",
       " 0.2529427027676571,\n",
       " 0.5889255678238341,\n",
       " 0.0,\n",
       " 0.41253177989255346,\n",
       " 0.7371988402300139,\n",
       " 0.3391602052736161,\n",
       " 0.0,\n",
       " 0.5531464700081437,\n",
       " 0.6263548016201019,\n",
       " 0.0,\n",
       " 0.3589542101716347,\n",
       " 0.3903800499921017,\n",
       " 0.7606993035979727,\n",
       " 0.0,\n",
       " 0.5505591812421098,\n",
       " 0.725855982823772,\n",
       " 0.4828791064230483,\n",
       " 0.76724922449719,\n",
       " 0.19635793579928928,\n",
       " 0.0,\n",
       " 0.5033818535333272,\n",
       " 0.27487633291429087,\n",
       " 0.0,\n",
       " 0.4646307801739275,\n",
       " 0.7085912584660702,\n",
       " 0.6020941629041773,\n",
       " 0.0,\n",
       " 0.7345331258714773,\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b26dadd7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10160/2419378044.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mtt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;31m# from sklearn.neighbors import NearestNeighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# tt=tt.detach().numpy().transpose()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 't1' is not defined"
     ]
    }
   ],
   "source": [
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# npNeigh=t1.detach().numpy().transpose()\n",
    "# nbrs=NearestNeighbors(n_neighbors=200,algorithm='ball_tree').fit(npNeigh[0:9021+1,:])\n",
    "\n",
    "#distances,indices=nbrs.kneighbors(npNeigh[9022:10189,:])\n",
    "#gr=nbrs.kneighbors_graph(npNeigh[0:9021+1,:]).toarray()\n",
    "def calcG(ID):\n",
    "    if ID>200:\n",
    "        ID=200\n",
    "    c=1\n",
    "    somm=0\n",
    "    while c<=ID:\n",
    "        somm+=1/(math.log2(1+c))\n",
    "        c+=1\n",
    "    return somm\n",
    "KNN=200\n",
    "def evalAcc(T,S,kneigh):\n",
    "    T=T.detach().numpy().transpose()\n",
    "    neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(T)\n",
    "    dist,ind=neigh.kneighbors(T)\n",
    "    print(dist)\n",
    "    acc=[]\n",
    "    for k in S:\n",
    "        summ=0\n",
    "        ideal=gs.A[k,:].sum().item()  #gs\n",
    "        den=calcG(ideal)\n",
    "        c=1\n",
    "        if den==0:  #There is the problem of the distance for the people without neighboorhood\n",
    "            continue\n",
    "        for j in ind[k][1:]:\n",
    "            if gs.A[k][j]!=0:\n",
    "                summ+= 1/(math.log2(1+c))\n",
    "            else:\n",
    "                continue\n",
    "            c+=1\n",
    "        summ/=den\n",
    "        acc.append(summ)\n",
    "    return acc\n",
    "\n",
    "#\n",
    "tt=t1[:,:train_[-1]+1]\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# tt=tt.detach().numpy().transpose()\n",
    "# nbrs=NearestNeighbors(n_neighbors=200+1,algorithm='ball_tree').fit(tt)\n",
    "\n",
    "# distances,indices=nbrs.kneighbors(tt)    \n",
    "evalAcc(tt,set(train_),200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a25e10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def batch_size(rang,bs=32):\n",
    "    m=[]\n",
    "    while len(rang)!=0:\n",
    "        l=set()\n",
    "        while len(l)<bs:\n",
    "            if len(rang)==0:\n",
    "                m.append(l)\n",
    "                return m\n",
    "            else:\n",
    "                r=choice(rang)\n",
    "                sample=rang.pop(rang.index(r))\n",
    "\n",
    "                l.add(sample)\n",
    "            \n",
    "        m.append(l)\n",
    "        \n",
    "    return m\n",
    "c=batch_size(list(range(100)),bs=32)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9b83c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafeb294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "\n",
    "print(randrange(-5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(mat,row,col):\n",
    "        col=sorted(list(col))\n",
    "        ma=torch.zeros((mat.shape[0],len(col)))\n",
    "        c=0\n",
    "        if row==set():\n",
    "            for k in col:\n",
    "                ma[:,c]=mat[:,k]\n",
    "                c+=1\n",
    "            return [col,ma]\n",
    "        else:\n",
    "            row=sorted(list(row))\n",
    "            return mat[row[0]:(row[-1]+1),col[0]:(col[-1]+1)]\n",
    "\n",
    "def tfunc(n_feat,es,V):\n",
    "    t=torch.zeros((n_feat,X.shape[1]))\n",
    "    print(t.shape,es.shape)\n",
    "    V=sorted(list(V))\n",
    "    c=0\n",
    "    for k in V:\n",
    "        t[:,k]=es[:,c]\n",
    "        c+=1\n",
    "    return t\n",
    "tfunc(2613,E,V[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521f8338",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X=gs.X\n",
    "V=gs.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e648f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(mat,row,col):\n",
    "        col=sorted(list(col))\n",
    "        \n",
    "        c=0\n",
    "        if row==set():\n",
    "            ma=torch.zeros((mat.shape[0],len(col)))\n",
    "            for k in col:\n",
    "                ma[:,c]=mat[:,k]\n",
    "                c+=1\n",
    "            return ma\n",
    "        else:\n",
    "            row=torch.tensor(sorted(list(row)))\n",
    "            col=torch.tensor(col)\n",
    "            ma=torch.index_select(mat,0,row)\n",
    "            ma=torch.index_select(ma,1,col)\n",
    "            return ma\n",
    "            \n",
    "def tfunc(n_feat,es,V):\n",
    "    t=torch.zeros((n_feat,X.shape[1]))\n",
    "    l=select1(es,set(),V)\n",
    "    V=l[0]\n",
    "    es=l[1]\n",
    "    c=0\n",
    "    for k in V:\n",
    "        t[:,k]=es[:,c]\n",
    "        c+=1\n",
    "    return t\n",
    "select(A,{1,54,63},{56,876,900})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ed9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0340cc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
