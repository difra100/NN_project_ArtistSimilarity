{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e657a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from requests_html import HTML,HTMLSession\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from random import choice\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd20535",
   "metadata": {},
   "source": [
    "## Loading of the dataset Olga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c407599",
   "metadata": {},
   "outputs": [],
   "source": [
    "olga=pd.read_csv('olga.csv')\n",
    "#olga[olga.partition=='train'].count()   #train 0-14138, #val 14139-15905, #test 15906-17673"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3712d1b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class DatasetOlga(): #In this class, we obtain through different methods the main characteristics of the graph of artists\n",
    "                     # thanks to the available information in the olga dataset\n",
    "    def __init__(self,olga):\n",
    "        self.olga=olga\n",
    "        self.mb=olga.musicbrainz_id\n",
    "        self.artists={} #Needed for obtaining the mapping from musicbrainz to the allmusic ids\n",
    "        self.l=len(self.mb)\n",
    "        self.d={}       #Needed for obtaining a dict. where keys are artists, and values are the artists similar to them, based on self.artists\n",
    "        self.NI={}      #Dict. that will contain the artist's features\n",
    "    \n",
    "    def get_mapping(self,i): #This method returns the allmusic page of an artist (if exists), given his id from the dataset \n",
    "        response = requests.get(f'https://musicbrainz.org/ws/2/artist/{str(self.mb[i])}?inc=url-rels&fmt=json')\n",
    "        if response.ok:\n",
    "            data = response.json()\n",
    "            refs = [r['url']['resource'] for r in data['relations'] if r['type'] == 'allmusic']        \n",
    "            return refs[0] if len(refs) != 0 else \"Not found\"\n",
    "\n",
    "        \n",
    "\n",
    "    def get_mappingList(self,init,end,increm=500):\n",
    "        Lmusicbrainz_id=self.mb[init:end] #We can specify the range of the artists of our interest, for the purpose of this NN task\n",
    "        length=len(Lmusicbrainz_id)       #we will take all of them into consideration.\n",
    "        c=0\n",
    "        for i in range(len(Lmusicbrainz_id)):\n",
    "            mapp=self.get_mapping(i)   #get_mapping method again.\n",
    "            if mapp==None:\n",
    "                while mapp==None:\n",
    "                    mapp=self.get_mapping(i)\n",
    "                    \n",
    "            if mapp!=\"Not found\":   #Some of the ids has not a respective allmusic id, so we lose that information\n",
    "                mapp=str(mapp)      #Mapp are strings of links\n",
    "                key=mapp[-12:]\n",
    "                self.artists[key]=i\n",
    "            c+=1\n",
    "            if c%increm==0 or c==30:\n",
    "                    print(\"{}/{} artists were processed\".format(c,length)) #This is just to keep track of the processed artist\n",
    "                    \n",
    "            \n",
    "        self.save_data(self.artists,'MsbMapped1.json')  #We do save the Artists Ids map, this function, when called, takes a lot\n",
    "                                                        #of time, for this reason its result is already saved in the file:\n",
    "        return self.artists                             # 'MsbMapped1.json'\n",
    "    \n",
    "    \n",
    "    def get_GraphDict(self,name='MsbMapped1.json',increm=500):\n",
    "        session=HTMLSession()\n",
    "        c=0 #Counter\n",
    "        artID=self.load_data(name) #We load the mapped artists (between MusicBrainz Ids, and AllMusic Ids)\n",
    "        length=len(artID.keys())\n",
    "        for k in artID.keys(): #dict of mapped mbids, this has to be computed before from getmapping\n",
    "            if k!=None:\n",
    "                url='https://www.allmusic.com/artist/'+ k+ '/related' #k is just the code, every link for the artist is distinguished \n",
    "                r=session.get(url)                                    #by a unique code in the link.\n",
    "                sess=r.html.find('body',first=True)\n",
    "                div=sess.find('.overflow-container')                  #The information of the related artists are exctracted\n",
    "                divn=div[0]                                           #from the html of the allmusic's related web page\n",
    "                divn=divn.find('.content-container')\n",
    "                divn=divn[0]\n",
    "                divn=divn.find('.content')\n",
    "                divn=divn[0]\n",
    "                divn=divn.find('section',first=True)\n",
    "                if divn==None:\n",
    "                    self.d[artID[k]]=[] #That artist has not related artists (or we have missing information)\n",
    "                    continue\n",
    "                artists=divn.find('li')\n",
    "                artistL=[]\n",
    "\n",
    "\n",
    "                for i in range(len(artists)):\n",
    "                    art=artists[i]\n",
    "                    art=art.find('a')            #We look for all the k's related artists links\n",
    "                    link=list(art[0].absolute_links)[0] #Absolute_link returns a one-element set, that we convert into a list and\n",
    "                    link=str(link)[-12:]                #we get its code\n",
    "                    if link in artID.keys(): #g is the dict of all the mapped musicbrainz_ids\n",
    "                        artistL.append(self.artists[link]) #Some of the related artists may not be in the musicbrainz_ids list.\n",
    "                self.d[artID[k]]=artistL\n",
    "                c+=1\n",
    "                if c%increm==0 or c==30:\n",
    "                    print(\"{}/{} artists were processed\".format(c,length))\n",
    "        self.save_data(self.d,'graphSimilarities1.json') #Here we save the connection amongst the artists, obtained with this method\n",
    "        print(\"Done...\")     #Also it takes some time to process, for this reason the result of this method can be \n",
    "        return self.d        #found at the 'graphSimilarities.json' file.\n",
    "    \n",
    "    def save_data(self,dicti,name):\n",
    "        jfile = open(name, \"w\")\n",
    "        jfile = json.dump(dicti, jfile)\n",
    "    \n",
    "    def load_data(self,name):\n",
    "        jfile = open(name, \"r\")\n",
    "        dicti = json.load(jfile)\n",
    "        return dicti\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f2be61",
   "metadata": {},
   "source": [
    "## Graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145ae3a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_features=2613\n",
    "class Graph():  #The purpose of this class is to construct the graph of artists, in particular the Adjacency matrix A, and the  \n",
    "                # node features tensor X\n",
    "        \n",
    "    def __init__(self,mapfile,gfile):  #The expected files are the ones mentioned before.\n",
    "        self.mfile=self.load_data(mapfile)\n",
    "        self.gfile=self.load_data(gfile)\n",
    "        self.A=torch.zeros((len(self.mfile),len(self.mfile)))\n",
    "        self.X=torch.zeros((n_features,len(self.mfile)))\n",
    "        self.ord=sorted(list(map(int,self.gfile.keys())))\n",
    "        self.enc1={}\n",
    "        self.enc2={}\n",
    "    \n",
    "    #With the preprocessing step at the previous cell we have lost some information\n",
    "    #and also the ordering of the artists, so i have defined a method that for each previous artist index\n",
    "    #we can encode it to a new ordered list of artists.\n",
    "    \n",
    "    \n",
    "    def encoding1(self):   #From ordered to unordered, Dict are not ordered data structures, so is better to order them before\n",
    "        for k in range(len(self.mfile)): #This encoding is used to get the Instance matrix\n",
    "            self.enc1[k]=self.ord[k]\n",
    "        return self.enc1\n",
    "    \n",
    "    def encoding2(self):   #From unordered to ordered,  From real number, to ordered one.\n",
    "        for k in range(len(self.mfile)): #This encoding is used to get the Adjacency matrix\n",
    "            self.enc2[self.ord[k]]=k\n",
    "        return self.enc2\n",
    "    \n",
    "    def get_instance(self,instances,df=False):#We take the features centroid, obtained from 25 track from artists discographies.\n",
    "        X=np.load(instances)                  #The instances file is provided by the repository mentioned in the paper.\n",
    "        X=torch.from_numpy(X).requires_grad_(True) #We take the allmusicIDs, which contain the key of the artists for which we haven't \n",
    "        c=0                                        # lost information\n",
    "        enc=self.encoding1()\n",
    "        for k in self.mfile:\n",
    "            z=enc[c]\n",
    "            self.X[:,c]=X[z] \n",
    "            c+=1\n",
    "        return self.X\n",
    "    \n",
    "    def get_adjacency(self,symmetry=False,df=False):  #The hypothesis could be either a symmetric matrix (paper), or not.\n",
    "        enc=self.encoding2()\n",
    "        for k in self.gfile:\n",
    "            c1=enc[int(k)]\n",
    "            for j in self.gfile[k]:\n",
    "                c2=enc[int(j)]\n",
    "                if self.A[c2,c1]==1 and symmetry==True:\n",
    "                    continue\n",
    "                self.A[c1,c2]=1\n",
    "                if symmetry:\n",
    "                    self.A[c2,c1]=1\n",
    "\n",
    "            \n",
    "        return self.A\n",
    "    \n",
    "    \n",
    "    def load_data(self,name):\n",
    "        jfile = open(name, \"r\")\n",
    "        dicti = json.load(jfile)\n",
    "        return dicti\n",
    "    \n",
    "g=Graph('MsbMapped.json','graphSimilarities.json')\n",
    "X1=g.get_instance('acousticbrainz.npy')\n",
    "A1=g.get_adjacency(symmetry=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e080eafd",
   "metadata": {},
   "source": [
    "# GraphSAGE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a1121362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we have some hyperparamters, and also the list of ordered artists, and their indices with respect their own set (train,val,test).\n",
    "outf=[2613,512,128,32,100] #Train: 0:9021, #Val: 9022:10189, #Test: 10190:11260\n",
    "train_=list(range(0,9021+1)) #Train set, without val\n",
    "train=list(range(0,10189+1)) #Train set, with val\n",
    "val=list(range(9022,10189+1))\n",
    "test=list(range(10190,11260+1))\n",
    "KNN=200       #K-nearest-neighbors for the evaluation metrics.\n",
    "device=torch.device('cuda')\n",
    "class GraphSAGE(nn.Module):\n",
    "    \n",
    "    def __init__(self,X,A):\n",
    "        super(GraphSAGE,self).__init__()\n",
    "        self.A=A #Tensors version of adjacency matrix and Instances\n",
    "        self.X=X    \n",
    "        self.V={}  #In this dictionary we insert the tracing of a certain mini_batch, needed for the forward step\n",
    "        self.l11=nn.Linear(outf[0],1024)\n",
    "        self.l12=nn.Linear(3637,outf[1])\n",
    "        self.l21=nn.Linear(outf[1],256)\n",
    "        self.l22=nn.Linear(768,outf[2])\n",
    "        self.l31=nn.Linear(outf[2],64)\n",
    "        self.l32=nn.Linear(192,outf[3])\n",
    "        self.FC11=nn.Linear(outf[1],256)\n",
    "        self.FC12=nn.Linear(outf[2],256)\n",
    "        self.FC13=nn.Linear(outf[3],256)\n",
    "        \n",
    "        self.FC2=nn.Linear(256,256)\n",
    "        self.out=nn.Linear(256,100) #final output layer\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self,V,L):\n",
    "        K=L+1                      #We add a number, because if we have three layers, we need to count also the batch\n",
    "        self.V[K]=set(V)\n",
    "        for k in range(K-1,0,-1):\n",
    "            d=set()\n",
    "            for idx in self.V[k+1]: \n",
    "                d=d.union(self.get_n(idx))\n",
    "                \n",
    "            self.V[k]=d\n",
    "        \n",
    "        Es=self.select(self.X,set(),self.V[1])\n",
    "        for k in range(0,K-1):                   #k starts from 0, 0 is associated with the first layer, 1 with the second and so on....\n",
    "            t=self.tfunc(outf[k],Es,self.V[k+1]) #tfunc is a matrix that has 0 for the column outside the mini-batch sets,  \n",
    "            Esn=self.select(t,set(),self.V[k+2]) #and has the transformed vectors for the columns that belongs to the mini_batch set\n",
    "            An=self.select(self.A,self.V[k+1],self.V[k+2]) #We do select either the vectors from X, and from A\n",
    "            \n",
    "            #Graph convolution block, according to the GraphSAGE structure described in the paper.\n",
    "            \n",
    "            if k==0:\n",
    "                N=torch.mm(torch.transpose(F.elu(self.l11(torch.transpose(Es,0,1))),0,1),An)\n",
    "                \n",
    "                Es=F.elu(self.l12(torch.transpose(torch.cat((N,Esn)),0,1)))\n",
    "            if k==1:\n",
    "                N=torch.mm(torch.transpose(F.elu(self.l21(torch.transpose(Es,0,1))),0,1),An)\n",
    "                \n",
    "                Es=F.elu(self.l22(torch.transpose(torch.cat((N,Esn)),0,1)))\n",
    "            if k==2:\n",
    "                N=torch.mm(torch.transpose(F.elu(self.l31(torch.transpose(Es,0,1))),0,1),An)\n",
    "                \n",
    "                Es=F.elu(self.l32(torch.transpose(torch.cat((N,Esn)),0,1)))\n",
    "            \n",
    "            Es=torch.transpose(F.normalize(Es,dim=0),0,1)\n",
    "        \n",
    "        #Fully connected layers. The input layer depends on the number of Graph layers.\n",
    "        \n",
    "        if L==1:                                         #There are different input dimensions, because they depend on the \n",
    "            Es=F.elu(self.FC11(torch.transpose(Es,0,1))) #output dimension returned by the GCN\n",
    "        elif L==2:\n",
    "            Es=F.elu(self.FC12(torch.transpose(Es,0,1)))\n",
    "        elif L==3:\n",
    "            Es=F.elu(self.FC13(torch.transpose(Es,0,1)))\n",
    "        Es=F.elu(self.FC2(Es))\n",
    "        Es=torch.transpose(self.out(Es),0,1) #Final linear layer that represents the obtained embedded space.\n",
    "\n",
    "        return Es\n",
    "            \n",
    "    def get_n(self,idx):    #This function is the neighbor's function. Given a batch index we get its neighborhood.\n",
    "        t=torch.nonzero(self.A[idx])\n",
    "        s=set()\n",
    "        \n",
    "        for k in t:\n",
    "            if t.shape[0]!=0:\n",
    "                s.add(k.item())\n",
    "        s.add(idx)     \n",
    "                \n",
    "        return s\n",
    "    def select(self,mat,row,col):  #Given a set of indices for rows or column or both, we get the respective elements.\n",
    "        col=sorted(list(col))      #This is applied when we get the t matrix.\n",
    "        \n",
    "        c=0\n",
    "        if row==set():\n",
    "            ma=torch.zeros((mat.shape[0],len(col)))\n",
    "            for k in col:\n",
    "                ma[:,c]=mat[:,k]\n",
    "                c+=1\n",
    "            return ma\n",
    "        else:\n",
    "            row=torch.tensor(sorted(list(row)))\n",
    "            col=torch.tensor(col)\n",
    "            ma=torch.index_select(mat,0,row)\n",
    "            ma=torch.index_select(ma,1,col)\n",
    "            return ma\n",
    "    \n",
    "    def tfunc(self,n_feat,es,V):               #This is the t function, which was previously described\n",
    "        t=torch.zeros((n_feat,self.X.shape[1]))\n",
    "        V=sorted(list(V))\n",
    "        c=0\n",
    "        for k in V:\n",
    "            t[:,k]=es[:,c]\n",
    "            c+=1\n",
    "        return t\n",
    "    def tfunc2(self,n_feat,es,V,prev):               #This tfunction is later used for the accuracy evaluation step\n",
    "        V=sorted(list(V))\n",
    "        c=0\n",
    "        for k in V:\n",
    "            prev[:,k]=es[:,c]\n",
    "            c+=1\n",
    "        return prev\n",
    "    def mini_batches(self,indices,bs=32): #This function generates a list of minibatches, of size bs\n",
    "        indicesN=indices.copy()           #sets are unordered data structure, so there is no need to shuffle them. \n",
    "        mbList=[]                         #Lists of lists of mini_batches indices \n",
    "        while len(indicesN)!=0:\n",
    "            mb=set()                      #Inner list, with the indices of a particular mini_batch\n",
    "            while len(mb)<bs:\n",
    "                if len(indicesN)==0:\n",
    "                    mbList.append(mb)\n",
    "                    return mbList\n",
    "                r=choice(indicesN)\n",
    "                sample=indicesN.pop(indicesN.index(r))\n",
    "                mb.add(sample)\n",
    "            mbList.append(mb)\n",
    "        return mbList          #obj.mini_batches(#,bs=128) #: train_,train,val,test, we get lists of list of batches from here\n",
    "    \n",
    "    \n",
    "    def calcG(self,ID):  #This method is used for the evaluation of accuracy, in particular it computes the denominator\n",
    "        if ID>200:       # as described in the paper.\n",
    "            ID=200\n",
    "        c=1\n",
    "        somm=0\n",
    "        while c<=ID:\n",
    "            somm+=1/(math.log2(1+c))\n",
    "            c+=1\n",
    "        return somm\n",
    "\n",
    "    def evalAcc(self,T,S,kneigh):  #This function is to compute accuracy for the test and train set. \n",
    "        T=T.detach().numpy().transpose()\n",
    "        neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(T)  #With the K-NN we get the nearest \n",
    "        dist,ind=neigh.kneighbors(T)                                                 #neighbors in the embedded.\n",
    "        acc=[]                          \n",
    "        for k in S:\n",
    "            summ=0\n",
    "            ideal=self.A[k,:].sum().item()  #gs\n",
    "            den=self.calcG(ideal)\n",
    "            c=1\n",
    "            if den==0:#There is the problem of the distance for the people without neighbors\n",
    "                continue  #1-(n/200) or ignore them.\n",
    "            for j in ind[k][1:]:\n",
    "                if self.A[k][j]!=0:\n",
    "                    summ+= 1/(math.log2(1+c))\n",
    "                else:\n",
    "                    continue\n",
    "                c+=1\n",
    "            summ/=den\n",
    "            acc.append(summ)\n",
    "        return acc\n",
    "    \n",
    "\n",
    "\n",
    "gs=GraphSAGE(X1,A1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bc95a5",
   "metadata": {},
   "source": [
    "### Here there will be the training step...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ff785ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "training=train_\n",
    "testing=val\n",
    "n_layer=1   #n_of graph conv.layer.\n",
    "batch_size=512 #This is the batch size used in the paper which insired artist similarity\n",
    "mbb=gs.mini_batches(training,bs=batch_size)\n",
    "num_epochs=1 #According to the paper there will be 50 epochs for each experiment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e580b5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch n°  1\n",
      "Evaluating the epoch n°  1\n",
      "Processesed epoch n° 1, \tTrain accuracy: 0.2365, \tTest accuracy: 0.3087\n",
      "done\n",
      "73.32841181755066\n"
     ]
    }
   ],
   "source": [
    "#With these lines of code we obtain the embedded space sample\n",
    "start=time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Processing epoch n° \",epoch+1)\n",
    "    num=int(len(training)/batch_size)+1     \n",
    "    for k in range(len(mbb)):\n",
    "        Ex=gs(mbb[k],n_layer)\n",
    "        #TODO: Loss function, Optimizer\n",
    "        name=\"C:\\\\Users\\\\Peppe\\\\OneDrive\\\\Desktop\\\\Università\\\\magistrale\\\\Neural_Networks\\\\MIR_project\\\\minibatches\\\\file\"+str(k)+\".pt\"\n",
    "        torch.save(Ex,name)\n",
    "\n",
    "    for k in range(len(mbb)):\n",
    "        name=\"C:\\\\Users\\\\Peppe\\\\OneDrive\\\\Desktop\\\\Università\\\\magistrale\\\\Neural_Networks\\\\MIR_project\\\\minibatches\\\\file\"+str(k)+\".pt\"\n",
    "        ex=torch.load(name)\n",
    "        \n",
    "        if k==0:\n",
    "            t1=gs.tfunc(outf[-1],ex,mbb[k])\n",
    "\n",
    "        else:\n",
    "            t1=gs.tfunc2(outf[-1],ex,mbb[k],t1)\n",
    "    print(\"Evaluating the epoch n° \",epoch+1)\n",
    "    accL1=gs.evalAcc(t1[:,:training[-1]+1],set(training),KNN)\n",
    "    t2=gs(set(testing),n_layer)\n",
    "    t2=gs.tfunc2(outf[-1],t2,set(testing),t1) #We integrate the testing set to the previous training set\n",
    "    accL2=gs.evalAcc(t2,set(testing),KNN)\n",
    "    TestAcc=sum(accL1)/len(accL1)\n",
    "    TrainAcc=sum(accL2)/len(accL2)\n",
    "    print(\"Processesed epoch n° {}, \\tTrain accuracy: {:.4f}, \\tTest accuracy: {:.4f}\".format((epoch+1),TrainAcc,TestAcc))\n",
    "    print(\"done\")\n",
    "end=time.time()\n",
    "print(end-start) #78 sec (1 graph layer), 132 sec (2 graph layers), 214 sec (3 graph layers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ed9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0340cc9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
