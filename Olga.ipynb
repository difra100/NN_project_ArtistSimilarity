{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e657a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from requests_html import HTML,HTMLSession\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from random import choice,randrange\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import math\n",
    "import time\n",
    "from torch_geometric.nn import GCNConv,GraphConv,GATConv,SAGEConv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd20535",
   "metadata": {},
   "source": [
    "## Loading of the dataset Olga\n",
    "\n",
    " - This is the dataset provided by the paper's author **'Artist similarity with Graph Neural Networks'**.\n",
    " - Along the columns we have information about the Musicbrainz_id of an artist, its partition in the dataset (train,val,test), and the AcousticBrainz low level features of the artist, taken from a sample of 25 songs. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c407599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>musicbrainz_id</th>\n",
       "      <th>partition</th>\n",
       "      <th>tracks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>c5b11a19-5ba6-4554-a65b-e505c3296d48</td>\n",
       "      <td>train</td>\n",
       "      <td>['0376162c-24b4-4b52-a351-185e40de9b71', '1607...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>252ca659-19c6-46e1-a464-c4b80300bb02</td>\n",
       "      <td>train</td>\n",
       "      <td>['029aebb5-4991-435a-90db-f56122c8fc4c', '0432...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b9f29919-5d08-498d-bcfc-fda33deceade</td>\n",
       "      <td>train</td>\n",
       "      <td>['073902fd-e188-416d-aeec-49c9c7fdf4d7', '0984...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1b396d40-a35a-4558-b292-0b2685f7ea8f</td>\n",
       "      <td>train</td>\n",
       "      <td>['0a3e1513-cc41-4234-9245-3f15adefef46', '1b07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>84cff711-6d4f-49b9-bc54-f4db4c7addfb</td>\n",
       "      <td>train</td>\n",
       "      <td>['02911df4-a535-4da0-bd0f-06027f31da6c', '091b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                        musicbrainz_id partition  \\\n",
       "0      0  c5b11a19-5ba6-4554-a65b-e505c3296d48     train   \n",
       "1      1  252ca659-19c6-46e1-a464-c4b80300bb02     train   \n",
       "2      2  b9f29919-5d08-498d-bcfc-fda33deceade     train   \n",
       "3      3  1b396d40-a35a-4558-b292-0b2685f7ea8f     train   \n",
       "4      4  84cff711-6d4f-49b9-bc54-f4db4c7addfb     train   \n",
       "\n",
       "                                              tracks  \n",
       "0  ['0376162c-24b4-4b52-a351-185e40de9b71', '1607...  \n",
       "1  ['029aebb5-4991-435a-90db-f56122c8fc4c', '0432...  \n",
       "2  ['073902fd-e188-416d-aeec-49c9c7fdf4d7', '0984...  \n",
       "3  ['0a3e1513-cc41-4234-9245-3f15adefef46', '1b07...  \n",
       "4  ['02911df4-a535-4da0-bd0f-06027f31da6c', '091b...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olga=pd.read_csv('olga.csv')   #train 0-14138, #val 14139-15905, #test 15906-17673 (indices)\n",
    "olga.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08648966",
   "metadata": {},
   "source": [
    "### How do we retrieve the Graph topology?\n",
    "\n",
    "- Thanks to the musicbrainz_id of each artist, we can get the link to its AllMusic profile, and from there we get also the information about its related artists. Each link is related to a unique artist, indeed we can spot a 12 numbers identifier for each of these.\n",
    "- After having obtained the AllMusic link for each artist in the dataset (if exists), we want to associate to each artist its related ones. We do this just for those that can be re-mapped in the dataset's musicbrainz_ids, because we have associated tracks features for those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3712d1b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class DatasetOlga(): #In this class, we obtain through different methods the main characteristics of the graph of artists\n",
    "                     # thanks to the available information in the olga dataset\n",
    "    def __init__(self,olga):\n",
    "        self.olga=olga\n",
    "        self.mb=olga.musicbrainz_id\n",
    "        self.artists={} #Needed for obtaining the mapping from musicbrainz to the allmusic ids\n",
    "        self.l=len(self.mb)\n",
    "        self.d={}       #Needed for obtaining a dict. where keys are artists, and values are the artists similar to them, based on self.artists\n",
    "        self.NI={}      #Dict. that will contain the artist's features\n",
    "    \n",
    "    def get_mapping(self,i): #This method returns the allmusic page of an artist (if exists), given his id from the dataset \n",
    "        response = requests.get(f'https://musicbrainz.org/ws/2/artist/{str(self.mb[i])}?inc=url-rels&fmt=json')\n",
    "        if response.ok:\n",
    "            data = response.json()\n",
    "            refs = [r['url']['resource'] for r in data['relations'] if r['type'] == 'allmusic']        \n",
    "            return refs[0] if len(refs) != 0 else \"Not found\"\n",
    "\n",
    "        \n",
    "\n",
    "    def get_mappingList(self,init,end,increm=500):\n",
    "        Lmusicbrainz_id=self.mb[init:end] #We can specify the range of the artists of our interest, for the purpose of this NN task\n",
    "        length=len(Lmusicbrainz_id)       #we will take all of them into consideration.\n",
    "        c=0\n",
    "        for i in range(len(Lmusicbrainz_id)):\n",
    "            mapp=self.get_mapping(i)   #get_mapping method again.\n",
    "            if mapp==None:\n",
    "                while mapp==None:\n",
    "                    mapp=self.get_mapping(i)\n",
    "                    \n",
    "            if mapp!=\"Not found\":   #Some of the ids has not a respective allmusic id, so we lose that information\n",
    "                mapp=str(mapp)      #Mapp are strings of links\n",
    "                key=mapp[-12:]\n",
    "                self.artists[key]=i\n",
    "            c+=1\n",
    "            if c%increm==0 or c==30:\n",
    "                    print(\"{}/{} artists were processed\".format(c,length)) #This is just to keep track of the processed artist\n",
    "                    \n",
    "            \n",
    "        self.save_data(self.artists,'MsbMapped1.json')  #We do save the Artists Ids map, this function, when called, takes a lot\n",
    "                                                        #of time, for this reason its result is already saved in the file:\n",
    "        return self.artists                             # 'MsbMapped1.json'\n",
    "    \n",
    "    \n",
    "    def get_GraphDict(self,name='MsbMapped1.json',increm=500):\n",
    "        session=HTMLSession()\n",
    "        c=0 #Counter\n",
    "        artID=self.load_data(name) #We load the mapped artists (between MusicBrainz Ids, and AllMusic Ids)\n",
    "        length=len(artID.keys())\n",
    "        for k in artID.keys(): #dict of mapped mbids, this has to be computed before from getmapping\n",
    "            if k!=None:\n",
    "                url='https://www.allmusic.com/artist/'+ k+ '/related' #k is just the code, every link for the artist is distinguished \n",
    "                r=session.get(url)                                    #by a unique code in the link.\n",
    "                sess=r.html.find('body',first=True)\n",
    "                div=sess.find('.overflow-container')                  #The information of the related artists are exctracted\n",
    "                divn=div[0]                                           #from the html of the allmusic's related web page\n",
    "                divn=divn.find('.content-container')\n",
    "                divn=divn[0]\n",
    "                divn=divn.find('.content')\n",
    "                divn=divn[0]\n",
    "                divn=divn.find('section',first=True)\n",
    "                if divn==None:\n",
    "                    self.d[artID[k]]=[] #That artist has not related artists (or we have missing information)\n",
    "                    continue\n",
    "                artists=divn.find('li')\n",
    "                artistL=[]\n",
    "\n",
    "\n",
    "                for i in range(len(artists)):\n",
    "                    art=artists[i]\n",
    "                    art=art.find('a')            #We look for all the k's related artists links\n",
    "                    link=list(art[0].absolute_links)[0] #Absolute_link returns a one-element set, that we convert into a list and\n",
    "                    link=str(link)[-12:]                #we get its code\n",
    "                    if link in artID.keys(): #g is the dict of all the mapped musicbrainz_ids\n",
    "                        artistL.append(self.artists[link]) #Some of the related artists may not be in the musicbrainz_ids list.\n",
    "                self.d[artID[k]]=artistL\n",
    "                c+=1\n",
    "                if c%increm==0 or c==30:\n",
    "                    print(\"{}/{} artists were processed\".format(c,length))\n",
    "        self.save_data(self.d,'graphSimilarities1.json') #Here we save the connection amongst the artists, obtained with this method\n",
    "        print(\"Done...\")     #Also it takes some time to process, for this reason the result of this method can be \n",
    "        return self.d        #found at the 'graphSimilarities.json' file.\n",
    "    \n",
    "    def save_data(self,dicti,name):\n",
    "        jfile = open(name, \"w\")\n",
    "        jfile = json.dump(dicti, jfile)\n",
    "    \n",
    "    def load_data(self,name):\n",
    "        jfile = open(name, \"r\")\n",
    "        dicti = json.load(jfile)\n",
    "        return dicti\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f2be61",
   "metadata": {},
   "source": [
    "## Graph construction\n",
    "\n",
    "- Once we have obtained the information necessary to construct the Graph topology, and stored them into two json files ('MsbMapped.json','graphSimilarities.json'), we still need to have the Graph data structure needed to feed a Graph Convolutional Network.\n",
    "\n",
    "- We then define the adjacency matrix of the graph from the 'graphSimilarities.json' previously obtained, and the features of each artist (or graph's node) are obtained from a numpy array stored in the file 'acousticbrainz.npy', such file was provided by the paper's authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145ae3a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_features=2613\n",
    "class Graph():  #The purpose of this class is to construct the graph of artists, in particular the Adjacency matrix A, and the  \n",
    "                # node features tensor X\n",
    "        \n",
    "    def __init__(self,mapfile,gfile):  #The expected files are the ones mentioned before.\n",
    "        self.mfile=self.load_data(mapfile)\n",
    "        self.gfile=self.load_data(gfile)\n",
    "        self.A=torch.zeros((len(self.mfile),len(self.mfile)))\n",
    "        self.X=torch.zeros((n_features,len(self.mfile)))\n",
    "        self.ord=sorted(list(map(int,self.gfile.keys())))\n",
    "        self.enc1={}\n",
    "        self.enc2={}\n",
    "    \n",
    "    #With the preprocessing step at the previous cell we have lost some information\n",
    "    #and also the ordering of the artists, so i have defined a method that for each previous artist index\n",
    "    #we can encode it to a new ordered list of artists.\n",
    "    \n",
    "    \n",
    "    def encoding1(self):   #From ordered to unordered, Dict are not ordered data structures, so is better to order them before\n",
    "        for k in range(len(self.mfile)): #This encoding is used to get the Instance matrix\n",
    "            self.enc1[k]=self.ord[k]\n",
    "        return self.enc1\n",
    "    \n",
    "    def encoding2(self):   #From unordered to ordered,  From real number, to ordered one.\n",
    "        for k in range(len(self.mfile)): #This encoding is used to get the Adjacency matrix\n",
    "            self.enc2[self.ord[k]]=k\n",
    "        return self.enc2\n",
    "    \n",
    "    def get_instance(self,instances,df=False):#We take the features centroid, obtained from 25 track from artists discographies.\n",
    "        X=np.load(instances)                  #The instances file is provided by the repository mentioned in the paper.\n",
    "        X=torch.from_numpy(X).requires_grad_(True) #We take the allmusicIDs, which contain the key of the artists for which we haven't \n",
    "        c=0                                        # lost information\n",
    "        enc=self.encoding1()\n",
    "        for k in self.mfile:\n",
    "            z=enc[c]\n",
    "            self.X[:,c]=X[z] \n",
    "            c+=1\n",
    "        return self.X\n",
    "    \n",
    "    def get_adjacency(self,symmetry=False,df=False):  #The hypothesis could be either a symmetric matrix (paper), or not.\n",
    "        enc=self.encoding2()\n",
    "        for k in self.gfile:\n",
    "            c1=enc[int(k)]\n",
    "            for j in self.gfile[k]:\n",
    "                c2=enc[int(j)]\n",
    "                if self.A[c2,c1]==1 and symmetry==True:\n",
    "                    continue\n",
    "                self.A[c1,c2]=1\n",
    "                if symmetry:\n",
    "                    self.A[c2,c1]=1\n",
    "\n",
    "            \n",
    "        return self.A\n",
    "    \n",
    "    \n",
    "    def load_data(self,name):\n",
    "        jfile = open(name, \"r\")\n",
    "        dicti = json.load(jfile)\n",
    "        return dicti\n",
    "    \n",
    "g=Graph('MsbMapped.json','graphSimilarities.json')\n",
    "X1=g.get_instance('acousticbrainz.npy')\n",
    "A1=g.get_adjacency(symmetry=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e080eafd",
   "metadata": {},
   "source": [
    "# GraphSAGE model\n",
    "\n",
    "- Once we also have the features for each instance, and the adjacency matrix of the graph, we can start to design the Graph Convolutional Layers, and the Fully Connected layers, as described in the paper.\n",
    "\n",
    "- Every feature vector has 2613 elements (low level features of the artist), our aim is to embed these vectors in a 100-dimensional space, and thanks to the Neural Networks we want to described it as a space where the similarity of each artist is described by the Euclidean distance.\n",
    "\n",
    "- The GraphNN that the paper's authors decided to use is the GraphSAGE model(SAGE stands for Sample and AGgregatE). \n",
    "\n",
    "- This approach propose a framework that generalizes the GCN to use trainable aggregation functions (beyond simple convolutions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1121362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we have some hyperparamters, and also the list of ordered artists, and their indices with respect their own set (train,val,test).\n",
    "outf=[2613,256,256,256,100] #Train: 0:9021, #Val: 9022:10189, #Test: 10190:11260\n",
    "train_=list(range(0,9021+1)) #Train set, without val\n",
    "train=list(range(0,10189+1)) #Train set, with val\n",
    "val=list(range(9022,10189+1))\n",
    "test=list(range(10190,11260+1))\n",
    "KNN=200       #K-nearest-neighbors for the evaluation metrics.\n",
    "device=torch.device('cuda')\n",
    "class GraphSAGE(nn.Module):\n",
    "    \n",
    "    def __init__(self,X,A,train_set,L):\n",
    "        super(GraphSAGE,self).__init__()\n",
    "        self.A=A #Tensors version of adjacency matrix and Instances\n",
    "        self.X=X    \n",
    "        self.COO=torch.load('COOA.pt')\n",
    "        self.train=train_set\n",
    "        self.L=L\n",
    "        self.lamb=0.8\n",
    "        self.diz=self.getDiz()\n",
    "        self.L12=nn.Linear(256,256)\n",
    "        self.L22=nn.Linear(512,256)\n",
    "        self.FC1=nn.Linear(2613,256)\n",
    "        self.FC2=nn.Linear(256,256)\n",
    "        self.FC3=nn.Linear(256,100)\n",
    "        self.f=nn.Linear(2613,5)\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    def forward(self,V):\n",
    "        Vdiz=self.tracing(V)\n",
    "        Es=torch.tensor(torch.transpose(self.select(self.X,set(),Vdiz[1]),0,1).tolist(),requires_grad=True)\n",
    "\n",
    "        for k in range(0,self.L):  \n",
    "            t=self.tfunc(Es.shape[1],torch.transpose(Es,0,1),Vdiz[k+1])  \n",
    "            Esn=torch.transpose(self.select(t,set(),Vdiz[k+2]),0,1) \n",
    "            An=self.select(self.A,Vdiz[k+1],Vdiz[k+2])\n",
    "            if k==0:\n",
    "                N=F.linear(torch.transpose(F.elu(self.FC1(Es)),0,1),torch.transpose(An,0,1))#.to(device)\n",
    "\n",
    "                Esn=self.f(Esn)\n",
    "                #x=torch.cat([N,torch.transpose(Esn,0,1)],dim=0)#.to(device)\n",
    "\n",
    "\n",
    "\n",
    "                Es=F.elu(self.L12(torch.transpose(N,0,1)))#.to(device)\n",
    "\n",
    "            if k==1:\n",
    "                N=F.linear(torch.transpose(F.elu(self.FC2(Es)),0,1),torch.transpose(An,0,1))\n",
    "                Es=F.elu(self.L22(torch.transpose(torch.cat((N,torch.transpose(Esn,0,1))),0,1)))\n",
    "\n",
    "            if k==2:\n",
    "                N=F.linear(torch.transpose(F.elu(self.FC2(Es)),0,1),torch.transpose(An,0,1))\n",
    "                Es=F.elu(self.L22(torch.transpose(torch.cat((N,torch.transpose(Esn,0,1))),0,1)))\n",
    "            Es=F.normalize(Es,dim=0)\n",
    "        out=self.FC2(Es)#.to(device)\n",
    "        out=self.FC2(out)#.to(device)\n",
    "        out=self.FC3(out)#.to(device)\n",
    "        return torch.transpose(out,0,1)\n",
    "    \n",
    "    def tracing(self,V):\n",
    "        Vdiz={}\n",
    "        K=self.L+1\n",
    "        Vdiz[K]=sorted(list(V))\n",
    "        for k in range(K-1,0,-1):\n",
    "            d=set()\n",
    "            for idx in Vdiz[k+1]: \n",
    "                d=d.union(self.get_n(idx))\n",
    "                \n",
    "            Vdiz[k]=d\n",
    "        return Vdiz\n",
    "            \n",
    "    def get_n(self,idx): #This function is the neighbor's function. Given a batch index we get its neighborhood.\n",
    "        t=torch.nonzero(self.A[idx])\n",
    "        s=set()\n",
    "        \n",
    "        for k in t:\n",
    "            if t.shape[0]!=0:\n",
    "                s.add(k.item())\n",
    "        s.add(idx)     \n",
    "                \n",
    "        return s\n",
    "    def select(self,mat,row,col):  #Given a set of indices for rows or column or both, we get the respective elements.\n",
    "        col=sorted(list(col))      #This is applied when we get the t matrix.\n",
    "        mat=mat\n",
    "        c=0\n",
    "        if row==set():\n",
    "            col=torch.tensor(col)\n",
    "            ma=torch.index_select(mat,1,col)\n",
    "            return ma\n",
    "        else:\n",
    "            row=torch.tensor(sorted(list(row)))\n",
    "            col=torch.tensor(col)\n",
    "            ma=torch.index_select(mat,0,row)\n",
    "            ma=torch.index_select(ma,1,col)\n",
    "            return ma\n",
    "    def tfunc(self,n_feat,es,V):               #This is the t function, which was previously described\n",
    "        t=torch.zeros((n_feat,self.X.shape[1]))\n",
    "        V=sorted(list(V))\n",
    "        c=0\n",
    "        for k in V:\n",
    "            t[:,k]=es[:,c]\n",
    "            c+=1\n",
    "        return t\n",
    "    def tfunc2(self,n_feat,es,V,prev):               #This tfunction is later used for the accuracy evaluation step\n",
    "        V=sorted(list(V))\n",
    "        c=0\n",
    "        for k in V:\n",
    "            prev[:,k]=es[:,c]\n",
    "            c+=1\n",
    "        return prev\n",
    "    \n",
    "    def getDiz(self):\n",
    "        diz={}\n",
    "        for k in range(self.COO.shape[1]):\n",
    "            cn=int(self.COO[0][k].item())\n",
    "            if cn>self.train[-1]:\n",
    "                break\n",
    "            \n",
    "            if cn not in diz:\n",
    "                diz[cn]=[[int(self.COO[1][k])]]\n",
    "                r=randrange(len(self.train))\n",
    "                while self.A[int(cn)][r]!=0:\n",
    "                    r=randrange(len(self.train))\n",
    "                diz[cn].append([r])\n",
    "            elif cn in diz:\n",
    "                diz[cn][0].append(int(self.COO[1][k]))\n",
    "                r=randrange(len(self.train))\n",
    "                while self.A[int(cn)][r]!=0:\n",
    "                    r=randrange(len(self.train))\n",
    "                diz[cn][1].append(r)\n",
    "                \n",
    "        return diz\n",
    "\n",
    "    def getHardN(self,a,t):\n",
    "        NEG=self.diz[a][0].copy()\n",
    "        if len(NEG)==1:\n",
    "            HN=self.forward([int(NEG[0])])\n",
    "            HN=torch.reshape(HN,(1,100))\n",
    "            return [HN,int(NEG[0])]\n",
    "        elif set(NEG).intersection(set(self.train))==set():\n",
    "            return \"no\"\n",
    "        \n",
    "        l=[]\n",
    "        c=0\n",
    "        while len(l)<4 and len(NEG)>0:\n",
    "            s=randrange(1000)\n",
    "            r=randrange(len(NEG))\n",
    "            random.seed(s)\n",
    "            NEG1=NEG\n",
    "            if NEG[r] in self.train and NEG[r] not in l:\n",
    "                l.append(int(NEG.pop(r)))\n",
    "                c=0\n",
    "            elif NEG1==NEG:\n",
    "                c+=1\n",
    "                if c==20:\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "        HNl=self.forward(l)\n",
    "        HNd1={}\n",
    "        HNd2={}\n",
    "        summ=0\n",
    "        if len(l)==1:\n",
    "            HN=self.forward([l[0]])\n",
    "            HN=torch.reshape(HN,(1,100))\n",
    "            return [HN,int(l[0])]\n",
    "        for k in l:\n",
    "            H1=HNl[:,l.index(k)]\n",
    "            HN=torch.reshape(H1,(100,1))\n",
    "            \n",
    "            dis=((t-HN)**2).sum().item()\n",
    "            HNd1[k]=H1\n",
    "            HNd2[k]=dis\n",
    "            summ+=dis\n",
    "        keys=list(HNd1.keys())\n",
    "        \n",
    "        for k in keys:\n",
    "            HNd2[k]/=summ\n",
    "            if HNd2[k]<=1-self.lamb:\n",
    "                HNd2.pop(k)\n",
    "                HNd1.pop(k)\n",
    "        key=min(HNd2,key=HNd2.get)\n",
    "        res=torch.reshape(HNd1[key],(1,100))\n",
    "        return [res,key]    \n",
    "        \n",
    "    def getHardP(self,a,t):\n",
    "        POS=self.diz[a][0].copy()\n",
    "        if len(POS)==1:\n",
    "            HP=self.forward([int(POS[0])])\n",
    "            HP=torch.reshape(HP,(1,100))\n",
    "            return [HP,int(POS[0])]\n",
    "        elif set(POS).intersection(set(self.train))==set():\n",
    "            return \"no\"\n",
    "        \n",
    "        l=[]\n",
    "        c=0\n",
    "        while len(l)<4 and len(POS)>0:\n",
    "            s=randrange(1000)\n",
    "            r=randrange(len(POS))\n",
    "            random.seed(s)\n",
    "            POS1=POS\n",
    "            if POS[r] in self.train and POS[r] not in l:\n",
    "                l.append(int(POS.pop(r)))\n",
    "                c=0\n",
    "            elif POS1==POS:\n",
    "                c+=1\n",
    "                if c==20:\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "        HPl=self.forward(l)\n",
    "        HPd1={}\n",
    "        HPd2={}\n",
    "        summ=0\n",
    "        if len(l)==1:\n",
    "            HP=self.forward([l[0]])\n",
    "            HP=torch.reshape(HP,(1,100))\n",
    "            return [HP,int(l[0])]\n",
    "        for k in l:\n",
    "            H1=HPl[:,l.index(k)]\n",
    "            HP=torch.reshape(H1,(100,1))\n",
    "            \n",
    "            dis=((t-HP)**2).sum().item()\n",
    "            HPd1[k]=H1\n",
    "            HPd2[k]=dis\n",
    "            summ+=dis\n",
    "        keys=list(HPd1.keys())\n",
    "        for k in keys:\n",
    "            HPd2[k]/=summ\n",
    "            if HPd2[k]>=self.lamb:\n",
    "                HPd2.pop(k)\n",
    "                HPd1.pop(k)\n",
    "        key=max(HPd2,key=HPd2.get)\n",
    "        res=torch.reshape(HPd1[key],(1,100))\n",
    "        \n",
    "        return [res,key]\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def mini_batches(self,indices,bs=32): #This function generates a list of minibatches, of size bs\n",
    "        indicesN=indices.copy()           #sets are unordered data structure, so there is no need to shuffle them. \n",
    "        mbList=[]                         #Lists of lists of mini_batches indices \n",
    "        while len(indicesN)!=0:\n",
    "            mb=set()                      #Inner list, with the indices of a particular mini_batch\n",
    "            while len(mb)<bs:\n",
    "                if len(indicesN)==0:\n",
    "                    mbList.append(mb)\n",
    "                    return mbList\n",
    "                r=choice(indicesN)\n",
    "                sample=indicesN.pop(indicesN.index(r))\n",
    "                mb.add(sample)\n",
    "            mbList.append(mb)\n",
    "        return mbList          #obj.mini_batches(#,bs=128) #: train_,train,val,test, we get lists of list of batches from here\n",
    "    \n",
    "    \n",
    "    def calcG(self,ID):  #This method is used for the evaluation of accuracy, in particular it computes the denominator\n",
    "        if ID>200:       # as described in the paper.\n",
    "            ID=200\n",
    "        c=1\n",
    "        somm=0\n",
    "        while c<=ID:\n",
    "            somm+=1/(math.log2(1+c))\n",
    "            c+=1\n",
    "        return somm\n",
    "\n",
    "    def evalAcc(self,T,S,kneigh,test_set):  #This function is to compute accuracy for the test and train set. \n",
    "        T=T.detach().numpy().transpose()\n",
    "        neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(T)#With the K-NN we get the nearest \n",
    "        dist,ind=neigh.kneighbors(T)   \n",
    "        acc=[]\n",
    "        A_acc=self.A[0:test_set[-1]+1,0:test_set[-1]+1]\n",
    "        for k in S:\n",
    "            summ=0\n",
    "            ideal=A_acc[k,:].sum().item()  #gs\n",
    "            den=self.calcG(ideal)\n",
    "            if den==0:#There is the problem of the distance for the people without neighbors\n",
    "                continue  #1-(n/200) or ignore them.\n",
    "            for j in range(len(ind[k][1:])):\n",
    "                if A_acc[k][ind[k][1:][j]]!=0:\n",
    "                    summ+= 1/(math.log2(1+(j+1)))\n",
    "                    \n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "            summ/=den\n",
    "            acc.append(summ)\n",
    "        return acc\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bc95a5",
   "metadata": {},
   "source": [
    "### Training step\n",
    "\n",
    "- In the following cell is possible to choose different hyperparameters to train the network.\n",
    "- In the hyperparameters tuning we must take into account: the number of layer (they try from 0 to 3 graph layers), the batch size, and the dimension of the projection matrices (in the aggregation step).\n",
    "- There are also other hyperparameters of course, but  we have the description in the paper for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ff785ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training=train_\n",
    "testing=val\n",
    "n_layer=1   #n_of graph conv.layer.\n",
    "batch_size=512 #This is the batch size used in the paper which insired artist similarity\n",
    "\n",
    "gs=GraphSAGE(X1,A1,training,n_layer)\n",
    "mbb=gs.mini_batches(training,bs=batch_size)\n",
    "num_epochs=21 #According to the paper there will be 50 epochs for each experiment \n",
    "out_feat=100\n",
    "triplet_loss = nn.TripletMarginLoss(margin=0.2, p=2)\n",
    "optimizer=torch.optim.Adam(gs.parameters(),lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9d0e87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e580b5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch n° 1\n",
      "Processing 1-th epoch: 1/18 mini-batch\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14588/4105087128.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmbbord\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiz\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                     \u001b[0mneg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                     \u001b[0mneg2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetHardN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmbbord\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mneg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mneg2\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m\"no\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                         \u001b[0mnegatives\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnegatives\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14588/3948709762.py\u001b[0m in \u001b[0;36mgetHardN\u001b[1;34m(self, a, t)\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0mHNl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[0mHNd1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mHNd2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14588/3948709762.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, V)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mVdiz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m             \u001b[0mEsn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mVdiz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mAn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mVdiz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mVdiz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#With these lines of code we obtain the embedded space sample\n",
    "start=time.time()\n",
    "#This path has to be modified.\n",
    "path=\"C:\\\\Users\\\\Peppe\\\\OneDrive\\\\Desktop\\\\Università\\\\magistrale\\\\Neural_Networks\\\\MIR_project\\\\minibatches\\\\graphsage\\\\trainval_batches\\\\file\"\n",
    "negativesD={}\n",
    "positivesD={}\n",
    "f=30\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Processing epoch n°\",epoch+1)\n",
    "    num=int(len(training)/batch_size)+1\n",
    "    startEP=time.time()\n",
    "    for k in range(len(mbb)):\n",
    "        print(\"Processing {}-th epoch: {}/{} mini-batch\".format(epoch+1,k+1,num))\n",
    "        startMB=time.time()\n",
    "        if k==f:\n",
    "            break\n",
    "        Ex=gs(mbb[k])\n",
    "        anchors=torch.transpose(Ex,0,1)\n",
    "        mbbord=sorted(list(mbb[k]))\n",
    "        if (epoch+1)%10==0 or epoch==0:\n",
    "            negativesD[k+1]=[]\n",
    "            positivesD[k+1]=[]\n",
    "            for j in range(len(mbbord)):\n",
    "                if mbbord[j] in gs.diz and j!=0:\n",
    "                    neg=torch.reshape(anchors[j],(100,1))\n",
    "                    neg2=gs.getHardN(mbbord[j],neg)\n",
    "                    if neg2!=\"no\":\n",
    "                        negatives=torch.cat((negatives,torch.reshape(neg2[0],(1,100))))\n",
    "                        negativesD[k+1].append(neg2[1])\n",
    "                        #print(\"Got neg\")\n",
    "                        pos=torch.reshape(anchors[j],(100,1))\n",
    "                        pos2=gs.getHardP(mbbord[j],pos)\n",
    "                        if pos2!=\"no\":\n",
    "                            positives=torch.cat((positives,pos2[0]))\n",
    "                            positivesD[k+1].append(pos2[1])\n",
    "                            #print(\"Got pos\")\n",
    "                            continue\n",
    "                        else:\n",
    "                            pos=torch.reshape(anchors[j],(1,100))\n",
    "                            positives=torch.cat((positives,pos))\n",
    "                            positivesD[k+1].append(mbbord[j])\n",
    "                            #print(\"Got pos2\")\n",
    "                            continue\n",
    "                        \n",
    "                    else:\n",
    "                        neg=torch.reshape(neg,(1,100))\n",
    "                        negatives=torch.cat((negatives,neg))\n",
    "                        negativesD[k+1].append(mbbord[j])\n",
    "                        #print(\"Got neg2\")\n",
    "                        pos=torch.reshape(anchors[j],(100,1))\n",
    "                        pos2=gs.getHardP(mbbord[j],pos)\n",
    "                        if pos2!=\"no\":\n",
    "                            positives=torch.cat((positives,pos2[0]))\n",
    "                            positivesD[k+1].append(pos2[1])\n",
    "                            #print(\"Got pos\")\n",
    "                            continue\n",
    "                        else:\n",
    "                            pos=torch.reshape(anchors[j],(1,100))\n",
    "                            positives=torch.cat((positives,pos))\n",
    "                            positivesD[k+1].append(mbbord[j])\n",
    "                            #print(\"Got pos2\")\n",
    "                            continue\n",
    "\n",
    "                    \n",
    "\n",
    "                elif j==0 and mbbord[j] in gs.diz:\n",
    "                    neg=gs.getHardN(mbbord[j],torch.reshape(anchors[j],(100,1)))\n",
    "                    pos=gs.getHardP(mbbord[j],torch.reshape(anchors[j],(100,1)))\n",
    "                    if neg!=\"no\":\n",
    "                        negatives=neg[0]\n",
    "                        negativesD[k+1].append(neg[1])\n",
    "                        if pos!=\"no\":\n",
    "                            positives=pos[0]\n",
    "                            positivesD[k+1].append(pos[1])\n",
    "                            continue\n",
    "                        else:\n",
    "                            positives=torch.reshape(anchors[j],(1,100))\n",
    "                            positivesD[k+1].append(mbbord[j])\n",
    "                            #print(\"Got pos2\")\n",
    "                            continue\n",
    "                        \n",
    "                    else:\n",
    "                        negatives=torch.reshape(anchors[j],(1,100))\n",
    "                        negativesD[k+1].append(mbbord[j])\n",
    "                        #print(\"Got neg2\")\n",
    "                        if pos!=\"no\":\n",
    "                            positives=pos[0]\n",
    "                            positivesD[k+1].append(pos[1])\n",
    "                            continue\n",
    "                        else:\n",
    "                            positives=torch.reshape(anchors[j],(1,100))\n",
    "                            positivesD[k+1].append(mbbord[j])\n",
    "                            #print(\"Got pos2\")\n",
    "                            continue\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                   \n",
    "\n",
    "                elif mbbord[j] not in gs.diz and j!=0:\n",
    "                    negatives=torch.cat((negatives,torch.reshape(anchors[j],(1,100))))\n",
    "                    negativesD[k+1].append(mbbord[j])\n",
    "                    pos=torch.reshape(anchors[j],(1,100))\n",
    "                    positives=torch.cat((positives,pos))\n",
    "                    positivesD[k+1].append(mbbord[j])\n",
    "                    #print(\"Got neg2 and pos2\")\n",
    "                    continue\n",
    "\n",
    "                elif mbbord[j] not in gs.diz and j==0:\n",
    "                    negatives=torch.reshape(anchors[j],(1,100))\n",
    "                    positives=torch.reshape(anchors[j],(1,100))\n",
    "                    negativesD[k+1].append(mbbord[j])\n",
    "                    positivesD[k+1].append(mbbord[j])\n",
    "                    #print(\"Got neg2 and pos2\")\n",
    "\n",
    "                    continue\n",
    "                \n",
    "        else:\n",
    "            negatives=gs(sorted(negativesD[k+1]))\n",
    "            positives=gs(sorted(positivesD[k+1]))\n",
    "            negatives=torch.transpose(negatives,0,1)\n",
    "            positives=torch.transpose(positives,0,1)\n",
    "            \n",
    "#             print(negatives.shape)\n",
    "#             print(positives.shape)\n",
    "#         positives=torch.randn((512,100))\n",
    "#         negatives=torch.randn((512,100))    \n",
    "        endD=time.time()\n",
    "        print(\"Halftime\",endD-startMB)\n",
    "        anchors=torch.transpose(gs(mbbord),0,1)\n",
    "        print(\"Computing loss function....\")\n",
    "        optimizer.zero_grad()\n",
    "        loss=triplet_loss(anchors,positives,negatives)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"Loss function is:\",loss.item())    \n",
    "        name=path+str(k)+\".pt\"\n",
    "        torch.save(torch.transpose(anchors,0,1),name)\n",
    "        endMB=time.time()\n",
    "        print(\"Requested time for processing {}/{} minibatch was {:.4f} secs.\".format(k+1,num,endMB-startMB))\n",
    "        \n",
    "    for k in range(len(mbb)):\n",
    "        name=path+str(k)+\".pt\"\n",
    "        ex=torch.load(name)\n",
    "        if k==f:\n",
    "            break\n",
    "        if k==0:\n",
    "            t1=gs.tfunc(out_feat,ex,mbb[k])\n",
    "\n",
    "        else:\n",
    "            t1=gs.tfunc2(out_feat,ex,mbb[k],t1)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        print(\"Evaluating the epoch n°\",epoch+1)\n",
    "        accL1=gs.evalAcc(t1[:,:training[-1]+1],set(training),KNN,training)\n",
    "        t2=gs(set(testing))\n",
    "        t2=gs.tfunc2(out_feat,t2,set(testing),t1) #We integrate the testing set to the previous training set\n",
    "        accL2=gs.evalAcc(t2,set(testing),KNN,testing)\n",
    "        TestAcc=sum(accL1)/len(accL1)\n",
    "        TrainAcc=sum(accL2)/len(accL2)\n",
    "        print(\"Processesed epoch n° {}, \\tTrain accuracy: {:.4f}, \\tTest accuracy: {:.4f}\".format((epoch+1),TrainAcc,TestAcc))\n",
    "        endEP=time.time()\n",
    "        print(\"Requested time for processing {}-th epoch was: {:.4f} secs.\".format(epoch+1,endEP-startEP))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bc73bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feat=2613\n",
    "class Provanet(nn.Module):\n",
    "    \n",
    "    def __init__(self,X,A,L):\n",
    "        super(Provanet,self).__init__()\n",
    "        self.X=X\n",
    "        self.A=A\n",
    "        self.Anew=torch.load('COOA.pt')\n",
    "        self.L=L\n",
    "        self.L12=nn.Linear(2869,256)\n",
    "        self.L22=nn.Linear(512,256)\n",
    "        \n",
    "        self.FC1=nn.Linear(2613,256)\n",
    "        self.FC2=nn.Linear(256,256)\n",
    "        self.FC3=nn.Linear(256,100)\n",
    "        \n",
    "        \n",
    "    def forward(self,V):\n",
    "        Vdiz=self.tracing(V)\n",
    "        Es=torch.tensor(torch.transpose(self.select(self.X,set(),Vdiz[1]),0,1).tolist(),requires_grad=True)\n",
    "\n",
    "            \n",
    "        for k in range(0,self.L):  \n",
    "            t=self.tfunc(Es.shape[1],torch.transpose(Es,0,1),Vdiz[k+1]) \n",
    "            Esn=torch.transpose(self.select(t,set(),Vdiz[k+2]),0,1) \n",
    "            An=self.select(self.A,Vdiz[k+1],Vdiz[k+2])\n",
    "            if k==0:\n",
    "                N=F.linear(torch.transpose(F.elu(self.FC1(Es)),0,1),torch.transpose(An,0,1))\n",
    "                \n",
    "                \n",
    "                x=torch.cat([N,torch.transpose(Esn,0,1)],dim=0)\n",
    "                \n",
    "                \n",
    "                Es=F.elu(self.FC2(torch.transpose(N,0,1)))\n",
    "#             if k==1:\n",
    "#                 N=F.linear(torch.transpose(F.elu(self.FC2(Es)),0,1),torch.transpose(An,0,1))\n",
    "#                 Es=F.elu(self.L22(torch.transpose(torch.cat((N,torch.transpose(Esn,0,1))),0,1)))\n",
    "\n",
    "#             if k==2:\n",
    "#                 N=F.linear(torch.transpose(F.elu(self.FC2(Es)),0,1),torch.transpose(An,0,1))\n",
    "#                 Es=F.elu(self.L22(torch.transpose(torch.cat((N,torch.transpose(Esn,0,1))),0,1)))\n",
    "            Es=F.normalize(Es,dim=0)\n",
    "        out=self.FC2(Es)#.to(device)\n",
    "        out=self.FC2(out)#.to(device)\n",
    "        out=self.FC3(out)#.to(device)\n",
    "        return torch.transpose(out,0,1)\n",
    "    \n",
    "    def select(self,mat,row,col):  \n",
    "        col=sorted(list(col))      \n",
    "        if row==set():\n",
    "            mat=torch.index_select(mat,1,torch.tensor(col))\n",
    "            return mat\n",
    "        else:\n",
    "            row=torch.tensor(sorted(list(row)))\n",
    "            col=torch.tensor(col)\n",
    "            ma=torch.index_select(mat,0,row)\n",
    "            ma=torch.index_select(ma,1,col)\n",
    "            return ma\n",
    "    def ConvertAtoCOO(self,SA):\n",
    "        Anew=torch.tensor([[],[]])\n",
    "        summ=SA.sum().item()\n",
    "        l=[]\n",
    "        for i in range(SA.shape[0]):\n",
    "            for j in range(SA.shape[1]):\n",
    "                if SA[i][j]!=0:\n",
    "                    Anew=torch.cat((Anew,torch.tensor([[i],[j]])),dim=1)\n",
    "                    if i not in l:\n",
    "                        l.append(i)\n",
    "        if summ!=Anew.shape[1]:\n",
    "            print(\"error in conversion....\")\n",
    "        return [Anew,l]\n",
    "    \n",
    "    def tracing(self,V):\n",
    "        Vdiz={}\n",
    "        K=self.L+1\n",
    "        Vdiz[K]=sorted(list(V))\n",
    "        for k in range(K-1,0,-1):\n",
    "            d=set()\n",
    "            for idx in Vdiz[k+1]: \n",
    "                d=d.union(self.get_n(idx))\n",
    "                \n",
    "            Vdiz[k]=d\n",
    "        return Vdiz\n",
    "        \n",
    "    \n",
    "    def get_n(self,idx):\n",
    "        t=torch.nonzero(self.A[idx])\n",
    "        s=set()\n",
    "        \n",
    "        for k in t:\n",
    "            if t.shape[0]!=0:\n",
    "                s.add(k.item())\n",
    "        s.add(idx) \n",
    "        \n",
    "        return s\n",
    "    \n",
    "    def tfunc(self,n_feat,es,V):               #This is the t function, which was previously described\n",
    "        t=torch.zeros((n_feat,self.X.shape[1]))\n",
    "        V=sorted(list(V))\n",
    "        c=0\n",
    "        for k in V:\n",
    "            t[:,k]=es[:,c]\n",
    "            c+=1\n",
    "        return t\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6372072",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5345783829689026\n",
      "0.2499292939901352\n",
      "0.05382080003619194\n",
      "0.010986328125\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "num_epochs=5\n",
    "\n",
    "n_layer=1\n",
    "p=Provanet(X1,A1,n_layer)\n",
    "P1=torch.randn((30,100))\n",
    "N1=torch.randn((30,100))\n",
    "#c1=Conf1(X1,A1)\n",
    "criterion=nn.TripletMarginLoss(margin=0.2,p=2)\n",
    "optimizer=torch.optim.Adam(p.parameters(),lr=0.1)\n",
    "for epoch in range(num_epochs):\n",
    "    y=torch.transpose(p([i for i in range(0,30)]),0,1)\n",
    "\n",
    "#     P1=torch.transpose(p([i for i in range(100,155)]),0,1)\n",
    "#     N1=torch.transpose(p([i for i in range(200,205)]),0,1)\n",
    "    start=time.time()\n",
    "    loss=criterion(y,P1,N1)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss.item())\n",
    "    end=time.time()\n",
    "#     print(end-start)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4789afc0",
   "metadata": {},
   "source": [
    "## First Configuration #1\n",
    "\n",
    "- Through torch_geometric we have to use the Coordinate format (COO), to represent the graph data structure.\n",
    "- Thus, in the class definition for the first configuration requested we have to convert our Adjacency matrix in a COO format.\n",
    "\n",
    "- Network design requested:\n",
    "\n",
    "1. Linear(Input, 256) \n",
    "2. Linear(256, 256)\n",
    "3. GCNConv(256, 256)\n",
    "4. GCNConv(256, 256)\n",
    "5. TripletLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f779093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input=2613\n",
    "train_=list(range(0,9021+1)) #Train set, without val\n",
    "train=list(range(0,10189+1)) #Train set, with val\n",
    "val=list(range(9022,10189+1))\n",
    "test=list(range(10190,11260+1))\n",
    "KNN=200       #K-nearest-neighbors for the evaluation metrics.\n",
    "class Conf1(nn.Module):\n",
    "    \n",
    "    def __init__(self,X,A):\n",
    "        super(Conf1,self).__init__()\n",
    "        self.X=X\n",
    "        self.A=A\n",
    "        self.l1=nn.Linear(n_input,256)\n",
    "        self.l2=nn.Linear(256,256)\n",
    "        self.GCN=GCNConv(256,256)\n",
    "        self.COO=torch.load('COOA.pt')\n",
    "        \n",
    "    \n",
    "    \n",
    "    def forward(self,V):\n",
    "        Xnew=torch.transpose(self.select(self.X,set(),V),0,1)\n",
    "        Anew=self.select(self.A,V,V)\n",
    "        print(\"I'm here\")\n",
    "        Anew=self.ConvertAtoCOO(Anew).type(torch.LongTensor)\n",
    "        Xnew=torch.tensor(Xnew.tolist(),requires_grad=True)\n",
    "        print(\"I'm here\")\n",
    "        Xnew=self.l1(Xnew)\n",
    "        Xnew=F.elu(Xnew)\n",
    "        Xnew=self.l2(Xnew)\n",
    "        Xnew=F.elu(Xnew)\n",
    "        Xnew=self.GCN(Xnew,Anew)\n",
    "        Xnew=F.elu(Xnew)\n",
    "        Xnew=self.GCN(Xnew,Anew)\n",
    "        print(\"I'm here\")\n",
    "        Xnew=F.elu(Xnew)\n",
    "        Xnew=torch.transpose(Xnew,0,1)\n",
    "        return Xnew\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def select(self,mat,row,col):  #Given a set of indices for rows or column or both, we get the respective elements.\n",
    "        col=sorted(list(col))      #This is applied when we get the t matrix.\n",
    "        \n",
    "        c=0\n",
    "        if row==set():\n",
    "            ma=torch.zeros((mat.shape[0],len(col)))\n",
    "            for k in col:\n",
    "                ma[:,c]=mat[:,k]\n",
    "                c+=1\n",
    "            return ma\n",
    "        else:\n",
    "            row=torch.tensor(sorted(list(row)))\n",
    "            col=torch.tensor(col)\n",
    "            ma=torch.index_select(mat,0,row)\n",
    "            ma=torch.index_select(ma,1,col)\n",
    "            return ma\n",
    "    def ConvertAtoCOO(self,SA):\n",
    "        Anew=torch.tensor([[],[]])\n",
    "        summ=SA.sum().item()\n",
    "        for i in range(SA.shape[0]):\n",
    "            for j in range(SA.shape[1]):\n",
    "                if SA[i][j]!=0:\n",
    "                    Anew=torch.cat((Anew,torch.tensor([[i],[j]])),dim=1)\n",
    "        if summ!=Anew.shape[1]:\n",
    "            print(\"error in conversion....\")\n",
    "        return Anew\n",
    "    \n",
    "    def mini_batches(self,indices,bs=32): #This function generates a list of minibatches, of size bs\n",
    "        indicesN=indices.copy()           #sets are unordered data structure, so there is no need to shuffle them. \n",
    "        mbList=[]                         #Lists of lists of mini_batches indices \n",
    "        while len(indicesN)!=0:\n",
    "            mb=set()                      #Inner list, with the indices of a particular mini_batch\n",
    "            while len(mb)<bs:\n",
    "                if len(indicesN)==0:\n",
    "                    mbList.append(mb)\n",
    "                    return mbList\n",
    "                r=choice(indicesN)\n",
    "                sample=indicesN.pop(indicesN.index(r))\n",
    "                mb.add(sample)\n",
    "            mbList.append(mb)\n",
    "        return mbList          #obj.mini_batches(#,bs=128) #: train_,train,val,test, we get lists of list of batches from here\n",
    "    def calcG(self,ID):  #This method is used for the evaluation of accuracy, in particular it computes the denominator\n",
    "        if ID>200:       # as described in the paper.\n",
    "            ID=200\n",
    "        c=1\n",
    "        somm=0\n",
    "        while c<=ID:\n",
    "            somm+=1/(math.log2(1+c))\n",
    "            c+=1\n",
    "        return somm\n",
    "\n",
    "    def evalAcc(self,T,S,kneigh):  #This function is to compute accuracy for the test and train set. \n",
    "        T=T.detach().numpy().transpose()\n",
    "        neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(T)  #With the K-NN we get the nearest \n",
    "        dist,ind=neigh.kneighbors(T)                                                 #neighbors in the embedded.\n",
    "        acc=[]                          \n",
    "        for k in S:\n",
    "            summ=0\n",
    "            ideal=self.A[k,:].sum().item()  #gs\n",
    "            den=self.calcG(ideal)\n",
    "            c=1\n",
    "            if den==0:#There is the problem of the distance for the people without neighbors\n",
    "                continue  #1-(n/200) or ignore them.\n",
    "            for j in ind[k][1:]:\n",
    "                if self.A[k][j]!=0:\n",
    "                    summ+= 1/(math.log2(1+c))\n",
    "                else:\n",
    "                    continue\n",
    "                c+=1\n",
    "            summ/=den\n",
    "            acc.append(summ)\n",
    "        return acc\n",
    "    \n",
    "    def tfunc(self,n_feat,es,V):               #This is the t function, which was previously described\n",
    "        t=torch.zeros((n_feat,self.X.shape[1]))\n",
    "        V=sorted(list(V))\n",
    "        c=0\n",
    "        for k in V:\n",
    "            t[:,k]=es[:,c]\n",
    "            c+=1\n",
    "        return t\n",
    "    def tfunc2(self,n_feat,es,V,prev):               #This tfunction is later used for the accuracy evaluation step\n",
    "        V=sorted(list(V))\n",
    "        c=0\n",
    "        for k in V:\n",
    "            prev[:,k]=es[:,c]\n",
    "            c+=1\n",
    "        return prev\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20e5c298",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9584/3161387801.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe28d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "d={1:[3,4,5,6],2:[3,21,2,3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e896bc2e",
   "metadata": {},
   "source": [
    "## Training step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a474560",
   "metadata": {},
   "source": [
    "## Second Configuration #2\n",
    "\n",
    "- Through torch_geometric we have to use the Coordinate format (COO), to represent the graph data structure.\n",
    "- Thus, in the class definition for the first configuration requested we have to convert our Adjacency matrix in a COO format.\n",
    "\n",
    "- Network design requested:\n",
    "\n",
    "1. GCNConv(Input, 256)\n",
    "2. GraphConv(256, 256)\n",
    "3. GCNConv(256, 256)\n",
    "4. GCNConv(256, 256)\n",
    "5. TripletLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "143b8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input=2613\n",
    "train_=list(range(0,9021+1)) #Train set, without val\n",
    "train=list(range(0,10189+1)) #Train set, with val\n",
    "val=list(range(9022,10189+1))\n",
    "test=list(range(10190,11260+1))\n",
    "KNN=200       #K-nearest-neighbors for the evaluation metrics.\n",
    "class Conf2(nn.Module):\n",
    "    \n",
    "    def __init__(self,X,A):\n",
    "        super(Conf2,self).__init__()\n",
    "        self.X=X\n",
    "        self.A=A\n",
    "        self.GCN1=GCNConv(n_input,256)\n",
    "        self.Graph=GraphConv(256,256)\n",
    "        self.GCN2=GCNConv(256,256)\n",
    "    \n",
    "    \n",
    "    def forward(self,V):\n",
    "        Xnew=torch.transpose(self.select(self.X,set(),V),0,1)\n",
    "        Anew=self.select(self.A,V,V)\n",
    "        Anew=self.ConvertAtoCOO(Anew).type(torch.LongTensor)\n",
    "        Xnew=self.GCN1(Xnew,Anew)\n",
    "        Xnew=F.elu(Xnew)\n",
    "        Xnew=self.Graph(Xnew,Anew)\n",
    "        Xnew=F.elu(Xnew)\n",
    "        Xnew=self.GCN2(Xnew,Anew)\n",
    "        Xnew=F.elu(Xnew)\n",
    "        Xnew=self.GCN2(Xnew,Anew)\n",
    "        Xnew=F.elu(Xnew)\n",
    "        Xnew=torch.transpose(Xnew,0,1)\n",
    "        return Xnew\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def select(self,mat,row,col):  #Given a set of indices for rows or column or both, we get the respective elements.\n",
    "        col=sorted(list(col))      #This is applied when we get the t matrix.\n",
    "        \n",
    "        c=0\n",
    "        if row==set():\n",
    "            ma=torch.zeros((mat.shape[0],len(col)))\n",
    "            for k in col:\n",
    "                ma[:,c]=mat[:,k]\n",
    "                c+=1\n",
    "            return ma\n",
    "        else:\n",
    "            row=torch.tensor(sorted(list(row)))\n",
    "            col=torch.tensor(col)\n",
    "            ma=torch.index_select(mat,0,row)\n",
    "            ma=torch.index_select(ma,1,col)\n",
    "            return ma\n",
    "    def ConvertAtoCOO(self,SA):\n",
    "        Anew=torch.tensor([[],[]])\n",
    "        summ=SA.sum().item()\n",
    "        for i in range(SA.shape[0]):\n",
    "            for j in range(SA.shape[1]):\n",
    "                if SA[i][j]!=0:\n",
    "                    Anew=torch.cat((Anew,torch.tensor([[i],[j]])),dim=1)\n",
    "        if summ!=Anew.shape[1]:\n",
    "            print(\"error in conversion....\")\n",
    "        return Anew\n",
    "    \n",
    "    def mini_batches(self,indices,bs=32): #This function generates a list of minibatches, of size bs\n",
    "        indicesN=indices.copy()           #sets are unordered data structure, so there is no need to shuffle them. \n",
    "        mbList=[]                         #Lists of lists of mini_batches indices \n",
    "        while len(indicesN)!=0:\n",
    "            mb=set()                      #Inner list, with the indices of a particular mini_batch\n",
    "            while len(mb)<bs:\n",
    "                if len(indicesN)==0:\n",
    "                    mbList.append(mb)\n",
    "                    return mbList\n",
    "                r=choice(indicesN)\n",
    "                sample=indicesN.pop(indicesN.index(r))\n",
    "                mb.add(sample)\n",
    "            mbList.append(mb)\n",
    "        return mbList          #obj.mini_batches(#,bs=128) #: train_,train,val,test, we get lists of list of batches from here\n",
    "    def calcG(self,ID):  #This method is used for the evaluation of accuracy, in particular it computes the denominator\n",
    "        if ID>200:       # as described in the paper.\n",
    "            ID=200\n",
    "        c=1\n",
    "        somm=0\n",
    "        while c<=ID:\n",
    "            somm+=1/(math.log2(1+c))\n",
    "            c+=1\n",
    "        return somm\n",
    "\n",
    "    def evalAcc(self,T,S,kneigh):  #This function is to compute accuracy for the test and train set. \n",
    "        T=T.detach().numpy().transpose()\n",
    "        neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(T)  #With the K-NN we get the nearest \n",
    "        dist,ind=neigh.kneighbors(T)                                                 #neighbors in the embedded.\n",
    "        acc=[]                          \n",
    "        for k in S:\n",
    "            summ=0\n",
    "            ideal=self.A[k,:].sum().item()  #gs\n",
    "            den=self.calcG(ideal)\n",
    "            c=1\n",
    "            if den==0:#There is the problem of the distance for the people without neighbors\n",
    "                continue  #1-(n/200) or ignore them.\n",
    "            for j in ind[k][1:]:\n",
    "                if self.A[k][j]!=0:\n",
    "                    summ+= 1/(math.log2(1+c))\n",
    "                else:\n",
    "                    continue\n",
    "                c+=1\n",
    "            summ/=den\n",
    "            acc.append(summ)\n",
    "        return acc\n",
    "    \n",
    "    def tfunc(self,n_feat,es,V):               #This is the t function, which was previously described\n",
    "        t=torch.zeros((n_feat,self.X.shape[1]))\n",
    "        V=sorted(list(V))\n",
    "        c=0\n",
    "        for k in V:\n",
    "            t[:,k]=es[:,c]\n",
    "            c+=1\n",
    "        return t\n",
    "    def tfunc2(self,n_feat,es,V,prev):               #This tfunction is later used for the accuracy evaluation step\n",
    "        V=sorted(list(V))\n",
    "        c=0\n",
    "        for k in V:\n",
    "            prev[:,k]=es[:,c]\n",
    "            c+=1\n",
    "        return prev\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8899a8",
   "metadata": {},
   "source": [
    "## Third Configuration #3\n",
    "\n",
    "- Through torch_geometric we have to use the Coordinate format (COO), to represent the graph data structure.\n",
    "- Thus, in the class definition for the first configuration requested we have to convert our Adjacency matrix in a COO format.\n",
    "\n",
    "- Network design requested:\n",
    "\n",
    "1. Linear(Input, 256)\n",
    "2. Linear(256, 256)\n",
    "3. GATConv(256, 256)\n",
    "4. GATConv(256, 256)\n",
    "5. TripletLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c6191ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input=2613\n",
    "train_=list(range(0,9021+1)) #Train set, without val\n",
    "train=list(range(0,10189+1)) #Train set, with val\n",
    "val=list(range(9022,10189+1))\n",
    "test=list(range(10190,11260+1))\n",
    "KNN=200       #K-nearest-neighbors for the evaluation metrics.\n",
    "class Conf3(nn.Module):\n",
    "    \n",
    "    def __init__(self,X,A):\n",
    "        super(Conf3,self).__init__()\n",
    "        self.X=X\n",
    "        self.A=A\n",
    "        self.l1=nn.Linear(n_input,256)\n",
    "        self.l2=nn.Linear(256,256)\n",
    "        self.GAT=GATConv(256,256)\n",
    "    \n",
    "    \n",
    "    def forward(self,V):\n",
    "        Xnew=torch.transpose(self.select(self.X,set(),V),0,1)\n",
    "        Anew=self.select(self.A,V,V)\n",
    "        Anew=self.ConvertAtoCOO(Anew).type(torch.LongTensor)\n",
    "        Xnew=self.l1(Xnew)\n",
    "        Xnew=F.elu(Xnew)\n",
    "        Xnew=self.l2(Xnew)\n",
    "        Xnew=F.elu(Xnew)\n",
    "        Xnew=self.GAT(Xnew,Anew)\n",
    "        Xnew=F.elu(Xnew)\n",
    "        Xnew=self.GAT(Xnew,Anew)\n",
    "        Xnew=F.elu(Xnew)\n",
    "        Xnew=torch.transpose(Xnew,0,1)\n",
    "        return Xnew\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def select(self,mat,row,col):  #Given a set of indices for rows or column or both, we get the respective elements.\n",
    "        col=sorted(list(col))      #This is applied when we get the t matrix.\n",
    "        \n",
    "        c=0\n",
    "        if row==set():\n",
    "            ma=torch.zeros((mat.shape[0],len(col)))\n",
    "            for k in col:\n",
    "                ma[:,c]=mat[:,k]\n",
    "                c+=1\n",
    "            return ma\n",
    "        else:\n",
    "            row=torch.tensor(sorted(list(row)))\n",
    "            col=torch.tensor(col)\n",
    "            ma=torch.index_select(mat,0,row)\n",
    "            ma=torch.index_select(ma,1,col)\n",
    "            return ma\n",
    "    def ConvertAtoCOO(self,SA):\n",
    "        Anew=torch.tensor([[],[]])\n",
    "        summ=SA.sum().item()\n",
    "        for i in range(SA.shape[0]):\n",
    "            for j in range(SA.shape[1]):\n",
    "                if SA[i][j]!=0:\n",
    "                    Anew=torch.cat((Anew,torch.tensor([[i],[j]])),dim=1)\n",
    "        if summ!=Anew.shape[1]:\n",
    "            print(\"error in conversion....\")\n",
    "        return Anew\n",
    "    \n",
    "    def mini_batches(self,indices,bs=32): #This function generates a list of minibatches, of size bs\n",
    "        indicesN=indices.copy()           #sets are unordered data structure, so there is no need to shuffle them. \n",
    "        mbList=[]                         #Lists of lists of mini_batches indices \n",
    "        while len(indicesN)!=0:\n",
    "            mb=set()                      #Inner list, with the indices of a particular mini_batch\n",
    "            while len(mb)<bs:\n",
    "                if len(indicesN)==0:\n",
    "                    mbList.append(mb)\n",
    "                    return mbList\n",
    "                r=choice(indicesN)\n",
    "                sample=indicesN.pop(indicesN.index(r))\n",
    "                mb.add(sample)\n",
    "            mbList.append(mb)\n",
    "        return mbList          #obj.mini_batches(#,bs=128) #: train_,train,val,test, we get lists of list of batches from here\n",
    "    def calcG(self,ID):  #This method is used for the evaluation of accuracy, in particular it computes the denominator\n",
    "        if ID>200:       # as described in the paper.\n",
    "            ID=200\n",
    "        c=1\n",
    "        somm=0\n",
    "        while c<=ID:\n",
    "            somm+=1/(math.log2(1+c))\n",
    "            c+=1\n",
    "        return somm\n",
    "\n",
    "    def evalAcc(self,T,S,kneigh):  #This function is to compute accuracy for the test and train set. \n",
    "        T=T.detach().numpy().transpose()\n",
    "        neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(T)  #With the K-NN we get the nearest \n",
    "        dist,ind=neigh.kneighbors(T)                                                 #neighbors in the embedded.\n",
    "        acc=[]                          \n",
    "        for k in S:\n",
    "            summ=0\n",
    "            ideal=self.A[k,:].sum().item()  #gs\n",
    "            den=self.calcG(ideal)\n",
    "            c=1\n",
    "            if den==0:#There is the problem of the distance for the people without neighbors\n",
    "                continue  #1-(n/200) or ignore them.\n",
    "            for j in ind[k][1:]:\n",
    "                if self.A[k][j]!=0:\n",
    "                    summ+= 1/(math.log2(1+c))\n",
    "                else:\n",
    "                    continue\n",
    "                c+=1\n",
    "            summ/=den\n",
    "            acc.append(summ)\n",
    "        return acc\n",
    "    \n",
    "    def tfunc(self,n_feat,es,V):               #This is the t function, which was previously described\n",
    "        t=torch.zeros((n_feat,self.X.shape[1]))\n",
    "        V=sorted(list(V))\n",
    "        c=0\n",
    "        for k in V:\n",
    "            t[:,k]=es[:,c]\n",
    "            c+=1\n",
    "        return t\n",
    "    def tfunc2(self,n_feat,es,V,prev):               #This tfunction is later used for the accuracy evaluation step\n",
    "        V=sorted(list(V))\n",
    "        c=0\n",
    "        for k in V:\n",
    "            prev[:,k]=es[:,c]\n",
    "            c+=1\n",
    "        return prev\n",
    "            \n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31428c7",
   "metadata": {},
   "source": [
    "## Fourth Configuration #4\n",
    "\n",
    "- Through torch_geometric we have to use the Coordinate format (COO), to represent the graph data structure.\n",
    "- Thus, in the class definition for the first configuration requested we have to convert our Adjacency matrix in a COO format.\n",
    "\n",
    "- Network design requested:\n",
    "\n",
    "1. GATConv(Input, 256)\n",
    "2. GATConv(256, 256)\n",
    "3. Linear(256, 256)\n",
    "4. Linear(256, 256)\n",
    "5. TripletLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd8e1414",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input=2613\n",
    "train_=list(range(0,9021+1)) #Train set, without val\n",
    "train=list(range(0,10189+1)) #Train set, with val\n",
    "val=list(range(9022,10189+1))\n",
    "test=list(range(10190,11260+1))\n",
    "KNN=200       #K-nearest-neighbors for the evaluation metrics.\n",
    "class Conf4(nn.Module):\n",
    "    \n",
    "    def __init__(self,X,A):\n",
    "        super(Conf4,self).__init__()\n",
    "        self.X=X\n",
    "        self.A=A\n",
    "        self.l1=nn.Linear(256,256)\n",
    "        self.l2=nn.Linear(256,256)\n",
    "        self.GAT1=GATConv(n_input,256)\n",
    "        self.GAT2=GATConv(256,256)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def forward(self,V):\n",
    "        Xnew=torch.transpose(self.select(self.X,set(),V),0,1)\n",
    "        Anew=self.select(self.A,V,V)\n",
    "        Anew=self.ConvertAtoCOO(Anew).type(torch.LongTensor)\n",
    "        Xnew=self.GAT1(Xnew,Anew)\n",
    "        Xnew=F.elu(Xnew)\n",
    "        Xnew=self.GAT2(Xnew,Anew)\n",
    "        Xnew=F.elu(Xnew)\n",
    "        Xnew=self.l1(Xnew)\n",
    "        Xnew=F.elu(Xnew)\n",
    "        Xnew=self.l2(Xnew)\n",
    "        Xnew=F.elu(Xnew)\n",
    "        Xnew=torch.transpose(Xnew,0,1)\n",
    "        return Xnew\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def select(self,mat,row,col):  #Given a set of indices for rows or column or both, we get the respective elements.\n",
    "        col=sorted(list(col))      #This is applied when we get the t matrix.\n",
    "        \n",
    "        c=0\n",
    "        if row==set():\n",
    "            ma=torch.zeros((mat.shape[0],len(col)))\n",
    "            for k in col:\n",
    "                ma[:,c]=mat[:,k]\n",
    "                c+=1\n",
    "            return ma\n",
    "        else:\n",
    "            row=torch.tensor(sorted(list(row)))\n",
    "            col=torch.tensor(col)\n",
    "            ma=torch.index_select(mat,0,row)\n",
    "            ma=torch.index_select(ma,1,col)\n",
    "            return ma\n",
    "    def ConvertAtoCOO(self,SA):\n",
    "        Anew=torch.tensor([[],[]])\n",
    "        summ=SA.sum().item()\n",
    "        for i in range(SA.shape[0]):\n",
    "            for j in range(SA.shape[1]):\n",
    "                if SA[i][j]!=0:\n",
    "                    Anew=torch.cat((Anew,torch.tensor([[i],[j]])),dim=1)\n",
    "        if summ!=Anew.shape[1]:\n",
    "            print(\"error in conversion....\")\n",
    "        return Anew\n",
    "    \n",
    "    def mini_batches(self,indices,bs=32): #This function generates a list of minibatches, of size bs\n",
    "        indicesN=indices.copy()           #sets are unordered data structure, so there is no need to shuffle them. \n",
    "        mbList=[]                         #Lists of lists of mini_batches indices \n",
    "        while len(indicesN)!=0:\n",
    "            mb=set()                      #Inner list, with the indices of a particular mini_batch\n",
    "            while len(mb)<bs:\n",
    "                if len(indicesN)==0:\n",
    "                    mbList.append(mb)\n",
    "                    return mbList\n",
    "                r=choice(indicesN)\n",
    "                sample=indicesN.pop(indicesN.index(r))\n",
    "                mb.add(sample)\n",
    "            mbList.append(mb)\n",
    "        return mbList          #obj.mini_batches(#,bs=128) #: train_,train,val,test, we get lists of list of batches from here\n",
    "    def calcG(self,ID):  #This method is used for the evaluation of accuracy, in particular it computes the denominator\n",
    "        if ID>200:       # as described in the paper.\n",
    "            ID=200\n",
    "        c=1\n",
    "        somm=0\n",
    "        while c<=ID:\n",
    "            somm+=1/(math.log2(1+c))\n",
    "            c+=1\n",
    "        return somm\n",
    "\n",
    "    def evalAcc(self,T,S,kneigh):  #This function is to compute accuracy for the test and train set. \n",
    "        T=T.detach().numpy().transpose()\n",
    "        neigh=NearestNeighbors(n_neighbors=(kneigh+1),algorithm='ball_tree').fit(T)  #With the K-NN we get the nearest \n",
    "        dist,ind=neigh.kneighbors(T)                                                 #neighbors in the embedded.\n",
    "        acc=[]                          \n",
    "        for k in S:\n",
    "            summ=0\n",
    "            ideal=self.A[k,:].sum().item()  #gs\n",
    "            den=self.calcG(ideal)\n",
    "            c=1\n",
    "            if den==0:#There is the problem of the distance for the people without neighbors\n",
    "                continue  #1-(n/200) or ignore them.\n",
    "            for j in ind[k][1:]:\n",
    "                if self.A[k][j]!=0:\n",
    "                    summ+= 1/(math.log2(1+c))\n",
    "                else:\n",
    "                    continue\n",
    "                c+=1\n",
    "            summ/=den\n",
    "            acc.append(summ)\n",
    "        return acc\n",
    "    \n",
    "    def tfunc(self,n_feat,es,V):               #This is the t function, which was previously described\n",
    "        t=torch.zeros((n_feat,self.X.shape[1]))\n",
    "        V=sorted(list(V))\n",
    "        c=0\n",
    "        for k in V:\n",
    "            t[:,k]=es[:,c]\n",
    "            c+=1\n",
    "        return t\n",
    "    def tfunc2(self,n_feat,es,V,prev):               #This tfunction is later used for the accuracy evaluation step\n",
    "        V=sorted(list(V))\n",
    "        c=0\n",
    "        for k in V:\n",
    "            prev[:,k]=es[:,c]\n",
    "            c+=1\n",
    "        return prev\n",
    "            \n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb895db8",
   "metadata": {},
   "source": [
    "# Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e42be3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=1\n",
    "\n",
    "if conf==1:\n",
    "    c=Conf1(X1,A1)\n",
    "elif conf==2:\n",
    "    c=Conf2(X1,A1)\n",
    "elif conf==3:\n",
    "    c=Conf3(X1,A1)\n",
    "elif conf==4:\n",
    "    c=Conf4(X1,A1)\n",
    "\n",
    "training=train  # train_, train\n",
    "if training==train_:\n",
    "    f=\"trainval\"\n",
    "elif training==train:\n",
    "    f=\"train\"\n",
    "testing=test  #val, test\n",
    "batch_size=512 \n",
    "mbb=c.mini_batches(training,bs=batch_size)\n",
    "num_epochs=1 #According to the paper there will be 50 epochs for each experiment \n",
    "out_feat=256\n",
    "triplet_loss = nn.TripletMarginLoss(margin=0.2, p=2)\n",
    "optimizer=torch.optim.Adam(c.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1216a931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of the 1-th net configuration, with the train partition\n",
      "Processing epoch n°  1\n",
      "2.893789529800415\n"
     ]
    }
   ],
   "source": [
    "#With these lines of code we obtain the embedded space sample\n",
    "start=time.time()\n",
    "#This path has to be modified.\n",
    "print(\"Training of the {}-th net configuration, with the {} partition\".format(conf,f))\n",
    "path=\"C:\\\\Users\\\\Peppe\\\\OneDrive\\\\Desktop\\\\Università\\\\magistrale\\\\Neural_Networks\\\\MIR_project\\\\minibatches\\\\conf\" + str(conf) + \"\\\\\"+ str(f)+\"_batches\\\\file\"\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Processing epoch n° \",epoch+1)\n",
    "    num=int(len(training)/batch_size)+1     \n",
    "    for k in range(len(mbb)):\n",
    "        if k==1:\n",
    "            break\n",
    "        Ex=c(mbb[k])\n",
    "        #TODO: Loss function, Optimizer\n",
    "        name=path+str(k)+\".pt\"\n",
    "        torch.save(Ex,name)\n",
    "    \n",
    "    for k in range(len(mbb)):\n",
    "        name=path+str(k)+\".pt\"\n",
    "        ex=torch.load(name)\n",
    "        \n",
    "        if k==0:\n",
    "            t1=c.tfunc(out_feat,ex,mbb[k])\n",
    "\n",
    "        else:\n",
    "            t1=c.tfunc2(out_feat,ex,mbb[k],t1)\n",
    "    break\n",
    "    print(\"Evaluating the epoch n° \",epoch+1)\n",
    "    accL1=c.evalAcc(t1[:,:training[-1]+1],set(training),KNN)\n",
    "    t2=c(set(testing))\n",
    "    t2=c.tfunc2(outf[-1],t2,set(testing),t1) #We integrate the testing set to the previous training set\n",
    "    accL2=c.evalAcc(t2,set(testing),KNN)\n",
    "    TestAcc=sum(accL1)/len(accL1)\n",
    "    TrainAcc=sum(accL2)/len(accL2)\n",
    "    print(\"Processesed epoch n° {}, \\tTrain accuracy: {:.4f}, \\tTest accuracy: {:.4f}\".format((epoch+1),TrainAcc,TestAcc))\n",
    "    print(\"done\")\n",
    "end=time.time()\n",
    "print(end-start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "901e2f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors=torch.randn(512,256,requires_grad=True)\n",
    "positives=torch.randn(512,256,requires_grad=True)\n",
    "negatives=torch.randn(512,256,requires_grad=True)\n",
    "tl=triplet_loss(Exnew,positives,negatives)    \n",
    "optimizer.zero_grad()\n",
    "tl.backward()\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6c20fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2361,  0.0504, -0.1597,  ...,  0.1840, -0.0293,  0.1570],\n",
       "        [-0.4286,  0.3652, -0.0188,  ..., -0.1241,  0.4381,  0.1229],\n",
       "        [-0.2130, -0.1340, -0.0267,  ..., -0.1231,  0.0229,  0.0788],\n",
       "        ...,\n",
       "        [-0.0843, -0.3757, -0.1636,  ..., -0.0185, -0.1687, -0.0337],\n",
       "        [-0.0625,  0.1115, -0.0804,  ...,  0.0591, -0.0250,  0.1086],\n",
       "        [-0.1814, -0.1057, -0.1372,  ...,  0.0546,  0.1489, -0.0676]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exnew=torch.transpose(Ex,0,1).tolist()\n",
    "Exnew=torch.tensor(Exnew,requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd877e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74843cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96772b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea608e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ddbfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d125af19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75991c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c155ac16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a51c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f504cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee289e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe33ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c0a5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b0e800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf21cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6872d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18d1962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2972f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e63e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
